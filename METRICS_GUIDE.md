# è¯„ä¼°æŒ‡æ ‡æŒ‡å—

## ä¸ºä»€ä¹ˆåœ¨æ¼æ´æ£€æµ‹ä¸­å¿…é¡»ä½¿ç”¨Macro-F1ï¼Ÿ

### æ ¸å¿ƒé—®é¢˜ï¼šç±»åˆ«ä¸å¹³è¡¡

åœ¨æ¼æ´æ£€æµ‹æ•°æ®é›†ä¸­ï¼Œå…¸å‹åˆ†å¸ƒå¦‚ä¸‹ï¼š

```
Benign (å®‰å…¨ä»£ç ):     ~90% (900/1000 samples)
Vulnerable (æ¼æ´ä»£ç ): ~10% (100/1000 samples)
```

åœ¨ä¸‰å±‚æ£€æµ‹ä¸­æ›´åŠ ä¸å¹³è¡¡ï¼š

```
Layer 1 (å¤§ç±»):
- Memory:    50 samples
- Injection: 30 samples
- Logic:     10 samples  â† å°‘æ•°ç±»
- Input:     8 samples   â† æ›´å°‘
- Crypto:    2 samples   â† æå°‘
```

### ä¸‰ç§F1è®¡ç®—æ–¹å¼

#### 1. **Macro-F1** â­ æ¨è

**å…¬å¼**:
$$\text{Macro-F1} = \frac{1}{N} \sum_{i=1}^{N} F1_i$$

**ç‰¹ç‚¹**:
- "ä¼—ç”Ÿå¹³ç­‰" - æ‰€æœ‰ç±»åˆ«åŒç­‰é‡è¦
- ä¸è€ƒè™‘æ ·æœ¬æ•°é‡
- å¼ºåˆ¶æ¨¡å‹åœ¨æ‰€æœ‰ç±»åˆ«ä¸Šéƒ½è¡¨ç°å¥½

**ç¤ºä¾‹**:
```python
Class A (900 samples): F1 = 0.95
Class B (100 samples): F1 = 0.30

Macro-F1 = (0.95 + 0.30) / 2 = 0.625
```

**è§£è¯»**: 0.625çš„åˆ†æ•°æ¸…æ¥šåœ°æ­ç¤ºäº†æ¨¡å‹åœ¨Class Bä¸Šçš„ç³Ÿç³•è¡¨ç°

---

#### 2. **Weighted-F1** âš ï¸ ä¸æ¨è

**å…¬å¼**:
$$\text{Weighted-F1} = \frac{\sum_{i=1}^{N} (F1_i \times S_i)}{S_{total}}$$

**ç‰¹ç‚¹**:
- "æŒ‰èµ„æ’è¾ˆ" - æ ·æœ¬å¤šçš„ç±»åˆ«æƒé‡å¤§
- è¢«å¤šæ•°ç±»ä¸»å¯¼
- å®¹æ˜“äº§ç”Ÿè¯¯å¯¼æ€§çš„é«˜åˆ†

**ç¤ºä¾‹**:
```python
Class A (900 samples): F1 = 0.95
Class B (100 samples): F1 = 0.30

Weighted-F1 = (0.95 Ã— 0.9) + (0.30 Ã— 0.1) = 0.885
```

**è§£è¯»**: 0.885çš„é«˜åˆ†æ©ç›–äº†æ¨¡å‹æ— æ³•æ£€æµ‹Class Bçš„äº‹å®ï¼

---

#### 3. **Micro-F1** â„¹ï¸ è¾…åŠ©å‚è€ƒ

**å…¬å¼**:
$$\text{Micro-F1} = \frac{TP_{global}}{TP_{global} + \frac{1}{2}(FP_{global} + FN_{global})}$$

**ç‰¹ç‚¹**:
- å…¨å±€è®¡ç®—
- åœ¨å¤šåˆ†ç±»ä¸­ç­‰åŒäºAccuracy
- åæ˜ æ•´ä½“è¡¨ç°

**ç¤ºä¾‹**:
```python
Total correct: 840/1000
Micro-F1 = 0.84 (= Accuracy)
```

---

## å®é™…æ¡ˆä¾‹å¯¹æ¯”

### åœºæ™¯1: å¤šæ•°ç±»è¡¨ç°å¥½ (å¸¸è§çš„åæ¨¡å‹)

```
Benign (900 samples):     F1 = 0.95 âœ…
Vulnerable (100 samples): F1 = 0.30 âŒ (70%çš„æ¼æ´è¢«æ¼æ£€!)

æŒ‡æ ‡å¯¹æ¯”:
- Macro-F1:    0.625 â† æ­ç¤ºçœŸç›¸
- Weighted-F1: 0.885 â† è¯¯å¯¼æ€§é«˜åˆ†!
- Micro-F1:    0.840

ç»“è®º: å¦‚æœåªçœ‹Weighted-F1ï¼Œä¼šè¯¯ä»¥ä¸ºè¿™æ˜¯ä¸ªå¥½æ¨¡å‹
```

### åœºæ™¯2: å°‘æ•°ç±»è¡¨ç°å¥½ (å¥½æ¨¡å‹)

```
Benign (900 samples):     F1 = 0.60
Vulnerable (100 samples): F1 = 0.95 âœ… (èƒ½å‡†ç¡®æ£€æµ‹æ¼æ´!)

æŒ‡æ ‡å¯¹æ¯”:
- Macro-F1:    0.775 â† è‚¯å®šå°‘æ•°ç±»çš„è´¡çŒ®
- Weighted-F1: 0.635 â† å¿½è§†å°‘æ•°ç±»çš„ä¼˜ç§€è¡¨ç°
- Micro-F1:    0.635

ç»“è®º: Weighted-F1æ²¡æœ‰ä½“ç°æ¨¡å‹åœ¨å…³é”®ç±»åˆ«ä¸Šçš„ä¼˜ç§€è¡¨ç°
```

---

## EvoPromptä¸­çš„å®ç°

### 1. è‡ªåŠ¨è®¡ç®—ä¸‰ç§F1

æ‰€æœ‰è¯„ä¼°éƒ½ä¼šè‡ªåŠ¨è®¡ç®—ï¼š

```python
metrics = {
    "layer1": {
        "accuracy": 0.80,
        "macro_f1": 0.65,      # â­ æ¨èå…³æ³¨
        "weighted_f1": 0.75,
        "micro_f1": 0.80,
        "macro_precision": 0.63,
        "macro_recall": 0.67,
    },
    ...
}
```

### 2. æ¯ä¸ªç±»åˆ«çš„è¯¦ç»†æŒ‡æ ‡

```python
"layer1_per_class": {
    "Memory": {
        "precision": 0.85,
        "recall": 0.80,
        "f1_score": 0.825,
        "support": 50
    },
    "Logic": {
        "precision": 0.40,
        "recall": 0.30,
        "f1_score": 0.343,
        "support": 10  # â† å°‘æ•°ç±»è¡¨ç°å·®!
    },
    ...
}
```

### 3. å¯è§†åŒ–æŠ¥å‘Š

```bash
uv run python scripts/train_three_layer.py --eval-samples 50
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
======================================================================
EVALUATION RESULTS
======================================================================

Total Samples: 50
Full Path Accuracy: 0.4200

----------------------------------------------------------------------
Layer 1 (Major Category)
----------------------------------------------------------------------
  Accuracy:        0.8000
  Macro-F1:        0.6500 â­ (æ¨è)
  Weighted-F1:     0.7500
  Micro-F1:        0.8000
  Macro-Precision: 0.6300
  Macro-Recall:    0.6700

----------------------------------------------------------------------
Layer 2 (Middle Category)
----------------------------------------------------------------------
  Accuracy:        0.7000
  Macro-F1:        0.5500 â­ (æ¨è)
  Weighted-F1:     0.6500
  Micro-F1:        0.7000
  Macro-Precision: 0.5200
  Macro-Recall:    0.5800

----------------------------------------------------------------------
Layer 3 (CWE)
----------------------------------------------------------------------
  Accuracy:        0.6000
  Macro-F1:        0.4500 â­ (æ¨è)
  Weighted-F1:     0.5500
  Micro-F1:        0.6000
  Macro-Precision: 0.4300
  Macro-Recall:    0.4700

======================================================================
ğŸ’¡ æ¨èå…³æ³¨æŒ‡æ ‡: Macro-F1
   åŸå› : æ¼æ´æ£€æµ‹ä¸­ç±»åˆ«ä¸å¹³è¡¡ï¼ŒMacro-F1ç¡®ä¿æ‰€æœ‰ç±»åˆ«éƒ½è¢«é‡è§†
======================================================================
```

---

## ä½¿ç”¨å»ºè®®

### 1. ä¸»è¦æŒ‡æ ‡

âœ… **Macro-F1** - ä¸»è¦ä¼˜åŒ–ç›®æ ‡

```python
# è®­ç»ƒæ—¶çš„é€‚åº”åº¦å‡½æ•°
fitness = metrics["layer1"]["macro_f1"] * 0.4 + \
          metrics["layer2"]["macro_f1"] * 0.3 + \
          metrics["layer3"]["macro_f1"] * 0.3
```

### 2. è¾…åŠ©æŒ‡æ ‡

ğŸ“Š **Weighted-F1** - å‚è€ƒæ•´ä½“è¡¨ç°
ğŸ“Š **Per-class F1** - æ‰¾å‡ºéœ€è¦æ”¹è¿›çš„ç±»åˆ«

### 3. é”™è¯¯åˆ†æ

é€šè¿‡Per-classæŒ‡æ ‡è¯†åˆ«é—®é¢˜ï¼š

```python
for class_name, metrics in layer1_per_class.items():
    if metrics["f1_score"] < 0.5:
        print(f"âš ï¸  {class_name} è¡¨ç°å·®: F1 = {metrics['f1_score']}")
        print(f"   Support: {metrics['support']} samples")
        print(f"   å»ºè®®: å¢åŠ è¯¥ç±»åˆ«çš„è®­ç»ƒæ ·æœ¬æˆ–ä¼˜åŒ–prompt")
```

---

## æ¼”ç¤ºè„šæœ¬

### æŸ¥çœ‹F1æŒ‡æ ‡å¯¹æ¯”

```bash
uv run python scripts/demo_f1_metrics.py
```

è¿™ä¸ªè„šæœ¬å±•ç¤ºï¼š
1. å¹³è¡¡æ•°æ®é›†ä¸­ä¸‰ç§F1çš„è¡¨ç°
2. ä¸å¹³è¡¡æ•°æ®é›†ä¸­çš„è¯¯å¯¼æ€§é—®é¢˜
3. ä¸ºä»€ä¹ˆå¿…é¡»ä½¿ç”¨Macro-F1

### å®é™…è¯„ä¼°

```bash
# åŸºç¡€è¯„ä¼° (ä¼šæ‰“å°è¯¦ç»†æŒ‡æ ‡)
uv run python scripts/train_three_layer.py --eval-samples 50

# RAGå¢å¼ºè¯„ä¼°
uv run python scripts/train_three_layer.py --use-rag --eval-samples 50
```

---

## è®ºæ–‡ä¸­çš„æŠ¥å‘Š

### æ¨èæ ¼å¼

åœ¨è®ºæ–‡ä¸­æŠ¥å‘Šæ‰€æœ‰ä¸‰ç§F1ï¼Œä½†å¼ºè°ƒMacro-F1ï¼š

| é…ç½® | Macro-F1 (â­) | Weighted-F1 | Micro-F1 |
|------|--------------|-------------|----------|
| åŸºçº¿ | 0.45 | 0.65 | 0.70 |
| + RAG | 0.55 (+22%) | 0.72 (+11%) | 0.78 (+11%) |
| + è®­ç»ƒ | 0.65 (+44%) | 0.80 (+23%) | 0.85 (+21%) |

**è¯´æ˜**: æˆ‘ä»¬ä½¿ç”¨Macro-F1ä½œä¸ºä¸»è¦æŒ‡æ ‡ï¼Œå› ä¸ºæ¼æ´æ£€æµ‹æ•°æ®é›†å­˜åœ¨ä¸¥é‡çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚Macro-F1èƒ½å¤Ÿç¡®ä¿æ¨¡å‹åœ¨æ‰€æœ‰CWEç±»åˆ«(åŒ…æ‹¬ç½•è§ä½†å…³é”®çš„å°‘æ•°ç±»)ä¸Šéƒ½ä¿æŒè‰¯å¥½æ€§èƒ½ã€‚

---

## ç›¸å…³æ–‡çŒ®

1. **Sokolova & Lapalme (2009)**: "A systematic analysis of performance measures for classification tasks"
   - è¯¦ç»†åˆ†æäº†å„ç§F1è®¡ç®—æ–¹å¼çš„é€‚ç”¨åœºæ™¯

2. **Grandini et al. (2020)**: "Metrics for Multi-Class Classification: an Overview"
   - å¤šåˆ†ç±»åœºæ™¯ä¸‹çš„æŒ‡æ ‡é€‰æ‹©æŒ‡å—

3. **Ling & Li (1998)**: "Data Mining for Direct Marketing: Problems and Solutions"
   - ä¸å¹³è¡¡æ•°æ®é›†çš„è¯„ä¼°æ–¹æ³•

---

## å¿«é€Ÿå‚è€ƒ

| æŒ‡æ ‡ | å…¬å¼ | é€‚ç”¨åœºæ™¯ | æ¨èåº¦ |
|------|------|----------|--------|
| Macro-F1 | mean(F1_i) | ç±»åˆ«ä¸å¹³è¡¡ + æ‰€æœ‰ç±»åˆ«éƒ½é‡è¦ | â­â­â­ |
| Weighted-F1 | sum(F1_i Ã— support_i) / total | æ ·æœ¬åˆ†å¸ƒä»£è¡¨çœŸå®æƒ…å†µ | âš ï¸ |
| Micro-F1 | global TP / total | æ•´ä½“å‡†ç¡®æ€§ | â„¹ï¸ |

**æ¼æ´æ£€æµ‹åœºæ™¯**: å¿…é¡»ä½¿ç”¨ **Macro-F1** â­

---

## æ€»ç»“

1. **ä½¿ç”¨Macro-F1ä½œä¸ºä¸»è¦æŒ‡æ ‡** - ç¡®ä¿æ‰€æœ‰ç±»åˆ«éƒ½è¢«å…¬å¹³å¯¹å¾…
2. **æŠ¥å‘Šæ‰€æœ‰ä¸‰ç§F1** - æä¾›å®Œæ•´çš„æ€§èƒ½è§†å›¾
3. **åˆ†æPer-class F1** - æ‰¾å‡ºéœ€è¦æ”¹è¿›çš„ç±»åˆ«
4. **é¿å…è¢«Weighted-F1è¯¯å¯¼** - å®ƒä¼šæ©ç›–å°‘æ•°ç±»çš„å¤±è´¥

è®°ä½ï¼š**åœ¨å®‰å…¨é¢†åŸŸï¼Œæˆ‘ä»¬ä¸èƒ½å¿½è§†ä»»ä½•ä¸€ä¸ªç±»åˆ«ï¼Œå“ªæ€•å®ƒåªæœ‰1ä¸ªæ ·æœ¬ï¼**
