#!/usr/bin/env python3
"""
增强版漏洞检测评估器
集成进化跟踪、统计分析和智能prompt优化功能
"""

import os
import time
from typing import List, Dict, Any, Optional
from tqdm import tqdm

from run_vulnerability_detection import VulnerabilityDetectionEvaluator
from evolution_tracker import EvolutionTracker, StatisticalAnalyzer, PromptOptimizer
from sven_llm_client import sven_llm_query


class EnhancedVulnerabilityEvaluator(VulnerabilityDetectionEvaluator):
    """增强版漏洞检测评估器"""
    
    def __init__(self, args):
        super().__init__(args)
        
        # 初始化进化跟踪系统
        experiment_name = f"vuln_detect_{args.dataset}_{args.evo_mode}_{int(time.time())}"
        self.tracker = EvolutionTracker(args.output, experiment_name)
        self.analyzer = StatisticalAnalyzer(self.tracker)
        self.optimizer = PromptOptimizer(self.tracker, self.analyzer)
        
        # 启动实验跟踪
        self.tracker.start_experiment({
            'dataset': args.dataset,
            'evo_mode': args.evo_mode,
            'popsize': args.popsize,
            'budget': args.budget,
            'sample_num': args.sample_num,
            'seed': args.seed
        })
        
        # 当前代数
        self.current_generation = 0
        
        # 存储详细结果
        self.detailed_results_cache = {}
        
        self.logger.info(f"🔬 Enhanced evaluator initialized with experiment: {experiment_name}")
    
    def forward(self, prompt_pre="", eval_src=None, ref_texts=None, output=None):
        """
        增强版前向传播，包含详细结果记录
        """
        start_time = time.time()
        
        if eval_src is None:
            eval_src = self.dev_src
        if ref_texts is None:
            ref_texts = self.dev_tgt
        
        # 构建完整的提示词
        full_prompts = []
        for code_snippet in eval_src:
            full_prompt = self.create_vulnerability_prompt(code_snippet, prompt_pre)
            full_prompts.append(full_prompt)
        
        # 使用LLM进行推理，并记录详细信息
        predictions, detailed_results = self.get_llm_predictions_with_details(full_prompts, ref_texts)
        
        # 标准化预测结果
        normalized_preds = self.normalize_predictions(predictions)
        
        # 计算评估指标
        scores = self.calculate_vulnerability_metrics(normalized_preds, ref_texts)
        
        # 记录到跟踪系统
        prompt_id = self.tracker.log_prompt(
            generation=self.current_generation,
            prompt_text=prompt_pre,
            scores=scores,
            detailed_results=detailed_results,
            parent_id=None,  # TODO: 在进化算法中设置父ID
            mutation_type=None  # TODO: 在进化算法中设置变异类型
        )
        
        # 缓存详细结果
        self.detailed_results_cache[prompt_pre] = {
            'prompt_id': prompt_id,
            'predictions': normalized_preds,
            'detailed_results': detailed_results,
            'scores': scores,
            'processing_time': time.time() - start_time
        }
        
        self.logger.info(f"📊 Prompt evaluated - F1: {scores[3]:.4f}, Acc: {scores[0]:.4f}, Time: {time.time() - start_time:.2f}s")
        
        return {"hypos": normalized_preds, "scores": scores}
    
    def get_llm_predictions_with_details(self, prompts: List[str], true_labels: List[str]) -> tuple:
        """获取LLM预测结果的同时记录详细信息"""
        predictions = []
        detailed_results = []
        
        try:
            self.logger.info(f"🔮 Starting enhanced batch prediction for {len(prompts)} prompts...")
            
            # 使用SVEN客户端的批量查询功能
            responses = sven_llm_query(
                data=prompts,
                client=self.client,
                task=False,
                temperature=0.0,
                delay=0.1
            )
            
            for i, (response, true_label) in enumerate(zip(responses, true_labels)):
                start_pred_time = time.time()
                
                if response == "error":
                    self.logger.warning(f"⚠️ Error in query {i+1}, using default prediction")
                    prediction = "benign"
                    confidence = 0.0
                else:
                    prediction = response
                    # 简单的置信度估算（基于响应内容）
                    confidence = self._estimate_confidence(response)
                
                predictions.append(prediction)
                
                # 记录详细结果
                detailed_results.append({
                    'input': prompts[i][:200] + '...' if len(prompts[i]) > 200 else prompts[i],
                    'predicted': prediction,
                    'true_label': true_label,
                    'correct': prediction.lower() in true_label.lower() or true_label.lower() in prediction.lower(),
                    'confidence': confidence,
                    'response_time': time.time() - start_pred_time,
                    'raw_response': response[:100] if isinstance(response, str) else str(response)[:100]
                })
                
        except Exception as e:
            self.logger.error(f"❌ Enhanced batch prediction failed: {e}")
            # 回退到原始方法
            predictions = self.get_llm_predictions(prompts)
            detailed_results = [
                {
                    'input': prompt[:100] + '...',
                    'predicted': pred,
                    'true_label': true_labels[i] if i < len(true_labels) else 'unknown',
                    'correct': False,
                    'confidence': 0.0,
                    'response_time': 0.0,
                    'raw_response': pred
                }
                for i, (prompt, pred) in enumerate(zip(prompts, predictions))
            ]
        
        return predictions, detailed_results
    
    def _estimate_confidence(self, response: str) -> float:
        """简单的置信度估算"""
        if not isinstance(response, str):
            return 0.0
        
        response_lower = response.lower()
        
        # 基于关键词的置信度
        high_confidence_words = ['definitely', 'clearly', 'obviously', 'certainly', 'vulnerable', 'safe']
        medium_confidence_words = ['likely', 'probably', 'seems', 'appears', 'might']
        low_confidence_words = ['maybe', 'possibly', 'unsure', 'unclear']
        
        if any(word in response_lower for word in high_confidence_words):
            return 0.9
        elif any(word in response_lower for word in medium_confidence_words):
            return 0.6
        elif any(word in response_lower for word in low_confidence_words):
            return 0.3
        else:
            return 0.5  # 默认置信度
    
    def start_generation(self, generation: int, population_prompts: List[str] = None):
        """开始新的一代"""
        self.current_generation = generation
        self.logger.info(f"🧬 Starting generation {generation}")
        
        if population_prompts:
            self.logger.info(f"📝 Population size: {len(population_prompts)}")
    
    def end_generation(self, generation: int, population_scores: List[float]):
        """结束当前代，进行分析和优化"""
        self.logger.info(f"🏁 Ending generation {generation}")
        
        # 记录代数统计
        self.tracker.log_generation(generation, population_scores)
        
        # 每2代进行一次深度分析
        if generation > 0 and generation % 2 == 0:
            self.perform_generation_analysis(generation)
        
        # 每3代进行一次优化建议
        if generation > 0 and generation % 3 == 0:
            self.generate_optimization_suggestions(generation)
    
    def perform_generation_analysis(self, generation: int):
        """执行代数分析"""
        self.logger.info(f"🔍 Performing analysis for generation {generation}")
        
        try:
            # 生成分析报告
            report = self.analyzer.generate_comprehensive_report(generation)
            
            # 保存分析报告
            report_file = os.path.join(self.public_out_path, f"analysis_gen_{generation}.json")
            import json
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"📄 Analysis report saved: {report_file}")
            
            # 输出关键洞察
            if 'llm_insights' in report and report['llm_insights']:
                self.logger.info("🧠 Key insights from LLM analysis:")
                insights_lines = report['llm_insights'].split('\n')[:5]  # 前5行
                for line in insights_lines:
                    if line.strip():
                        self.logger.info(f"   {line.strip()}")
                        
        except Exception as e:
            self.logger.error(f"❌ Analysis failed for generation {generation}: {e}")
    
    def generate_optimization_suggestions(self, generation: int):
        """生成优化建议"""
        self.logger.info(f"💡 Generating optimization suggestions for generation {generation}")
        
        try:
            # 获取最新的分析报告
            report = self.analyzer.generate_comprehensive_report(generation)
            
            # 生成优化策略
            strategies = self.optimizer.generate_optimization_strategies(report)
            
            # 保存策略
            strategies_file = os.path.join(self.public_out_path, f"strategies_gen_{generation}.txt")
            with open(strategies_file, 'w', encoding='utf-8') as f:
                f.write(f"Generation {generation} Optimization Strategies\n")
                f.write("=" * 50 + "\n\n")
                for i, strategy in enumerate(strategies, 1):
                    f.write(f"{i}. {strategy}\n\n")
            
            self.logger.info(f"💡 {len(strategies)} optimization strategies generated")
            self.logger.info(f"📄 Strategies saved: {strategies_file}")
            
            # 输出前3个策略
            for i, strategy in enumerate(strategies[:3], 1):
                self.logger.info(f"   Strategy {i}: {strategy[:100]}...")
                
        except Exception as e:
            self.logger.error(f"❌ Strategy generation failed for generation {generation}: {e}")
    
    def optimize_population(self, prompts: List[str], generation: int) -> List[str]:
        """优化种群（可选功能，由进化算法调用）"""
        self.logger.info(f"🔧 Optimizing population for generation {generation}")
        
        try:
            # 获取最新的优化策略
            report = self.analyzer.generate_comprehensive_report(generation-1)
            strategies = self.optimizer.generate_optimization_strategies(report)
            
            if not strategies:
                self.logger.warning("⚠️ No optimization strategies available, returning original prompts")
                return prompts
            
            # 批量优化
            optimized_prompts = self.optimizer.batch_optimize_population(prompts, strategies, generation)
            
            self.logger.info(f"✅ Population optimization completed")
            return optimized_prompts
            
        except Exception as e:
            self.logger.error(f"❌ Population optimization failed: {e}")
            return prompts
    
    def get_experiment_summary(self) -> Dict[str, Any]:
        """获取实验摘要"""
        summary = self.tracker.get_evolution_summary()
        
        # 添加额外信息
        summary['experiment_name'] = self.tracker.experiment_name
        summary['current_generation'] = self.current_generation
        summary['cache_entries'] = len(self.detailed_results_cache)
        
        return summary
    
    def export_results(self):
        """导出完整结果"""
        self.logger.info("📤 Exporting complete results...")
        
        try:
            # 导出实验摘要
            summary = self.get_experiment_summary()
            summary_file = os.path.join(self.public_out_path, "experiment_summary.json")
            
            import json
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            # 导出详细缓存
            cache_file = os.path.join(self.public_out_path, "detailed_cache.json")
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.detailed_results_cache, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"✅ Results exported to {self.public_out_path}")
            
        except Exception as e:
            self.logger.error(f"❌ Export failed: {e}")


# 工厂函数
def create_enhanced_evaluator(args) -> EnhancedVulnerabilityEvaluator:
    """创建增强版评估器"""
    return EnhancedVulnerabilityEvaluator(args)


if __name__ == "__main__":
    # 测试代码
    print("🧪 Testing Enhanced Vulnerability Evaluator...")
    
    class MockArgs:
        def __init__(self):
            self.dataset = "sven"
            self.task = "vul_detection"
            self.output = "./test_enhanced_outputs/"
            self.seed = 42
            self.evo_mode = "de"
            self.popsize = 5
            self.budget = 3
            self.sample_num = 20
    
    args = MockArgs()
    
    try:
        evaluator = create_enhanced_evaluator(args)
        print("✅ Enhanced evaluator created successfully!")
        
        # 模拟一些评估
        test_prompts = [
            "Analyze this code for vulnerabilities",
            "Check this code for security issues",
            "Review this code for potential threats"
        ]
        
        evaluator.start_generation(0, test_prompts)
        
        # 注意：这里不能实际运行forward，因为需要真实的API
        print("🎉 Enhanced evaluator test completed!")
        
    except Exception as e:
        print(f"❌ Test failed: {e}")
        import traceback
        traceback.print_exc()