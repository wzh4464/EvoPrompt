#!/usr/bin/env python3
"""
è¿›åŒ–è¿‡ç¨‹è·Ÿè¸ªå’Œæ™ºèƒ½åˆ†æç³»ç»Ÿ
ç”¨äºå­˜å‚¨promptå˜åŒ–ã€åˆ†æç»Ÿè®¡åå·®å¹¶æä¾›æ™ºèƒ½æ›´æ–°ç­–ç•¥
"""

import json
import os
import sqlite3
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from pathlib import Path

from sven_llm_client import sven_llm_init, sven_llm_query


class EvolutionTracker:
    """è¿›åŒ–è¿‡ç¨‹è·Ÿè¸ªå™¨"""
    
    def __init__(self, output_dir: str, experiment_name: str = None):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.experiment_name = experiment_name or f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # æ•°æ®åº“æ–‡ä»¶
        self.db_path = self.output_dir / f"{self.experiment_name}.db"
        self.init_database()
        
        # JSONæ–‡ä»¶ï¼ˆå¤‡ä»½å’Œå¯è¯»æ€§ï¼‰
        self.json_path = self.output_dir / f"{self.experiment_name}_results.json"
        
        # LLMå®¢æˆ·ç«¯ï¼ˆç”¨äºåˆ†æï¼‰
        self.llm_client = sven_llm_init()
        
        # å®éªŒé…ç½®
        self.config = {}
        
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºå®éªŒåŸºæœ¬ä¿¡æ¯è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS experiments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT UNIQUE,
                start_time TIMESTAMP,
                config TEXT,
                status TEXT DEFAULT 'running'
            )
        ''')
        
        # åˆ›å»ºè¿›åŒ–ä»£æ•°è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS generations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                experiment_id INTEGER,
                generation INTEGER,
                timestamp TIMESTAMP,
                best_score REAL,
                avg_score REAL,
                worst_score REAL,
                population_size INTEGER,
                FOREIGN KEY (experiment_id) REFERENCES experiments (id)
            )
        ''')
        
        # åˆ›å»ºpromptä¸ªä½“è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS prompts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                experiment_id INTEGER,
                generation INTEGER,
                prompt_text TEXT,
                score REAL,
                accuracy REAL,
                precision_val REAL,
                recall_val REAL,
                f1_score REAL,
                specificity REAL,
                parent_id INTEGER,
                mutation_type TEXT,
                timestamp TIMESTAMP,
                FOREIGN KEY (experiment_id) REFERENCES experiments (id)
            )
        ''')
        
        # åˆ›å»ºè¯¦ç»†é¢„æµ‹ç»“æœè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS predictions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                prompt_id INTEGER,
                sample_index INTEGER,
                input_text TEXT,
                predicted_label TEXT,
                true_label TEXT,
                is_correct BOOLEAN,
                confidence REAL,
                response_time REAL,
                FOREIGN KEY (prompt_id) REFERENCES prompts (id)
            )
        ''')
        
        # åˆ›å»ºç»Ÿè®¡åˆ†æè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analyses (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                experiment_id INTEGER,
                generation INTEGER,
                analysis_type TEXT,
                analysis_result TEXT,
                recommendations TEXT,
                timestamp TIMESTAMP,
                FOREIGN KEY (experiment_id) REFERENCES experiments (id)
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def start_experiment(self, config: Dict[str, Any]):
        """å¼€å§‹å®éªŒ"""
        self.config = config
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT OR REPLACE INTO experiments (name, start_time, config, status)
            VALUES (?, ?, ?, ?)
        ''', (self.experiment_name, datetime.now(), json.dumps(config), 'running'))
        
        self.experiment_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        print(f"ğŸš€ Started experiment: {self.experiment_name} (ID: {self.experiment_id})")
    
    def log_generation(self, generation: int, population_scores: List[float]):
        """è®°å½•ä¸€ä»£çš„ç»“æœ"""
        if not population_scores:
            return
            
        best_score = max(population_scores)
        avg_score = np.mean(population_scores)
        worst_score = min(population_scores)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO generations 
            (experiment_id, generation, timestamp, best_score, avg_score, worst_score, population_size)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (self.experiment_id, generation, datetime.now(), 
              best_score, avg_score, worst_score, len(population_scores)))
        
        conn.commit()
        conn.close()
        
        print(f"ğŸ“Š Generation {generation}: Best={best_score:.4f}, Avg={avg_score:.4f}, Worst={worst_score:.4f}")
    
    def log_prompt(self, generation: int, prompt_text: str, scores: List[float], 
                   detailed_results: List[Dict] = None, parent_id: int = None, 
                   mutation_type: str = None) -> int:
        """è®°å½•å•ä¸ªpromptçš„è¯¦ç»†ç»“æœ"""
        # è§£æscores [accuracy, precision, recall, f1, specificity]
        accuracy = scores[0] if len(scores) > 0 else 0
        precision_val = scores[1] if len(scores) > 1 else 0
        recall_val = scores[2] if len(scores) > 2 else 0
        f1_score = scores[3] if len(scores) > 3 else 0
        specificity = scores[4] if len(scores) > 4 else 0
        overall_score = f1_score  # ä½¿ç”¨F1ä½œä¸ºä¸»è¦åˆ†æ•°
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ’å…¥promptè®°å½•
        cursor.execute('''
            INSERT INTO prompts 
            (experiment_id, generation, prompt_text, score, accuracy, precision_val, 
             recall_val, f1_score, specificity, parent_id, mutation_type, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (self.experiment_id, generation, prompt_text, overall_score, accuracy,
              precision_val, recall_val, f1_score, specificity, parent_id, 
              mutation_type, datetime.now()))
        
        prompt_id = cursor.lastrowid
        
        # å¦‚æœæœ‰è¯¦ç»†ç»“æœï¼Œä¹Ÿå­˜å‚¨
        if detailed_results:
            for i, result in enumerate(detailed_results):
                cursor.execute('''
                    INSERT INTO predictions 
                    (prompt_id, sample_index, input_text, predicted_label, true_label, 
                     is_correct, confidence, response_time)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (prompt_id, i, 
                      result.get('input', ''),
                      result.get('predicted', ''),
                      result.get('true_label', ''),
                      result.get('correct', False),
                      result.get('confidence', 0.0),
                      result.get('response_time', 0.0)))
        
        conn.commit()
        conn.close()
        
        return prompt_id
    
    def get_generation_data(self, generation: int = None) -> pd.DataFrame:
        """è·å–æŒ‡å®šä»£æ•°çš„æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        
        if generation is not None:
            query = '''
                SELECT * FROM prompts 
                WHERE experiment_id = ? AND generation = ?
                ORDER BY score DESC
            '''
            df = pd.read_sql_query(query, conn, params=(self.experiment_id, generation))
        else:
            query = '''
                SELECT * FROM prompts 
                WHERE experiment_id = ?
                ORDER BY generation, score DESC
            '''
            df = pd.read_sql_query(query, conn, params=(self.experiment_id,))
        
        conn.close()
        return df
    
    def get_evolution_summary(self) -> Dict[str, Any]:
        """è·å–è¿›åŒ–è¿‡ç¨‹æ‘˜è¦"""
        conn = sqlite3.connect(self.db_path)
        
        # è·å–ä»£æ•°ç»Ÿè®¡
        generations_df = pd.read_sql_query('''
            SELECT * FROM generations 
            WHERE experiment_id = ?
            ORDER BY generation
        ''', conn, params=(self.experiment_id,))
        
        # è·å–æœ€ä½³prompts
        best_prompts_df = pd.read_sql_query('''
            SELECT generation, prompt_text, score, accuracy, precision_val, recall_val, f1_score
            FROM prompts 
            WHERE experiment_id = ?
            ORDER BY score DESC
            LIMIT 10
        ''', conn, params=(self.experiment_id,))
        
        conn.close()
        
        return {
            'generations': generations_df.to_dict('records'),
            'best_prompts': best_prompts_df.to_dict('records'),
            'total_generations': len(generations_df),
            'best_score': float(generations_df['best_score'].max()) if not generations_df.empty else 0,
            'final_avg_score': float(generations_df['avg_score'].iloc[-1]) if not generations_df.empty else 0
        }


class StatisticalAnalyzer:
    """ç»Ÿè®¡åˆ†æå™¨ - ä½¿ç”¨LLMåˆ†æå®éªŒæ•°æ®"""
    
    def __init__(self, tracker: EvolutionTracker):
        self.tracker = tracker
        self.llm_client = tracker.llm_client
    
    def analyze_generation_performance(self, generation: int) -> Dict[str, Any]:
        """åˆ†ææŸä¸€ä»£çš„æ€§èƒ½"""
        df = self.tracker.get_generation_data(generation)
        
        if df.empty:
            return {"error": "No data for this generation"}
        
        # åŸºç¡€ç»Ÿè®¡
        stats = {
            'generation': generation,
            'population_size': len(df),
            'score_stats': {
                'mean': float(df['score'].mean()),
                'std': float(df['score'].std()),
                'min': float(df['score'].min()),
                'max': float(df['score'].max()),
                'median': float(df['score'].median())
            },
            'metric_correlations': {
                'accuracy_f1_corr': float(df['accuracy'].corr(df['f1_score'])),
                'precision_recall_corr': float(df['precision_val'].corr(df['recall_val']))
            }
        }
        
        # è¯†åˆ«é«˜æ€§èƒ½å’Œä½æ€§èƒ½çš„promptç‰¹å¾
        top_prompts = df.nlargest(3, 'score')['prompt_text'].tolist()
        bottom_prompts = df.nsmallest(3, 'score')['prompt_text'].tolist()
        
        stats['top_prompts'] = top_prompts
        stats['bottom_prompts'] = bottom_prompts
        
        return stats
    
    def analyze_evolution_trends(self) -> Dict[str, Any]:
        """åˆ†ææ•´ä¸ªè¿›åŒ–è¶‹åŠ¿"""
        summary = self.tracker.get_evolution_summary()
        generations = summary['generations']
        
        if not generations:
            return {"error": "No generation data available"}
        
        # è¶‹åŠ¿åˆ†æ
        best_scores = [g['best_score'] for g in generations]
        avg_scores = [g['avg_score'] for g in generations]
        
        trends = {
            'score_improvement': best_scores[-1] - best_scores[0] if len(best_scores) > 1 else 0,
            'convergence_rate': self._calculate_convergence_rate(best_scores),
            'diversity_trend': self._calculate_diversity_trend(generations),
            'stagnation_periods': self._detect_stagnation(best_scores)
        }
        
        return {
            'trends': trends,
            'generations_count': len(generations),
            'best_overall_score': max(best_scores),
            'improvement_trajectory': best_scores
        }
    
    def _calculate_convergence_rate(self, scores: List[float]) -> float:
        """è®¡ç®—æ”¶æ•›é€Ÿåº¦"""
        if len(scores) < 2:
            return 0.0
        
        improvements = [scores[i] - scores[i-1] for i in range(1, len(scores))]
        recent_improvements = improvements[-3:] if len(improvements) >= 3 else improvements
        
        return np.mean(recent_improvements) if recent_improvements else 0.0
    
    def _calculate_diversity_trend(self, generations: List[Dict]) -> float:
        """è®¡ç®—å¤šæ ·æ€§è¶‹åŠ¿"""
        if len(generations) < 2:
            return 0.0
        
        diversity_scores = []
        for gen in generations:
            score_range = gen['best_score'] - gen['worst_score']
            diversity_scores.append(score_range)
        
        # å¤šæ ·æ€§æ˜¯å¦åœ¨ä¸‹é™ï¼ˆæ”¶æ•›ï¼‰
        recent_div = np.mean(diversity_scores[-3:]) if len(diversity_scores) >= 3 else diversity_scores[-1]
        early_div = np.mean(diversity_scores[:3]) if len(diversity_scores) >= 3 else diversity_scores[0]
        
        return recent_div - early_div
    
    def _detect_stagnation(self, scores: List[float], threshold: float = 0.001) -> int:
        """æ£€æµ‹åœæ»æœŸ"""
        if len(scores) < 3:
            return 0
        
        stagnant_count = 0
        for i in range(2, len(scores)):
            if abs(scores[i] - scores[i-1]) < threshold:
                stagnant_count += 1
            else:
                stagnant_count = 0
        
        return stagnant_count
    
    def llm_analyze_patterns(self, generation_data: Dict[str, Any]) -> str:
        """ä½¿ç”¨LLMåˆ†ææ¨¡å¼å’Œç»™å‡ºå»ºè®®"""
        analysis_prompt = f"""
ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜ï¼Œè¯·åˆ†æä»¥ä¸‹promptè¿›åŒ–å®éªŒçš„æ•°æ®ï¼š

## å®éªŒæ•°æ®æ‘˜è¦
- å½“å‰ä»£æ•°: {generation_data.get('generation', 'N/A')}
- ç§ç¾¤å¤§å°: {generation_data.get('population_size', 'N/A')}
- åˆ†æ•°ç»Ÿè®¡: {generation_data.get('score_stats', {})}

## é«˜æ€§èƒ½Prompts (Top 3):
{chr(10).join(f"{i+1}. {prompt}" for i, prompt in enumerate(generation_data.get('top_prompts', [])))}

## ä½æ€§èƒ½Prompts (Bottom 3):
{chr(10).join(f"{i+1}. {prompt}" for i, prompt in enumerate(generation_data.get('bottom_prompts', [])))}

è¯·åˆ†æï¼š
1. é«˜æ€§èƒ½å’Œä½æ€§èƒ½promptä¹‹é—´çš„å…³é”®å·®å¼‚
2. è¯†åˆ«å¯èƒ½å½±å“æ€§èƒ½çš„è¯­è¨€æ¨¡å¼ã€ç»“æ„æˆ–å…³é”®è¯
3. æŒ‡å‡ºå¯èƒ½çš„ç»Ÿè®¡å­¦åå·®æˆ–è¿‡æ‹Ÿåˆé—®é¢˜
4. ç»™å‡ºå…·ä½“çš„promptæ”¹è¿›å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œç»“æ„åŒ–è¾“å‡ºã€‚
"""
        
        try:
            analysis = sven_llm_query(analysis_prompt, self.llm_client, temperature=0.3)
            return analysis
        except Exception as e:
            return f"LLMåˆ†æå¤±è´¥: {str(e)}"
    
    def generate_comprehensive_report(self, generation: int = None) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        # è·å–æ•°æ®
        if generation is not None:
            gen_analysis = self.analyze_generation_performance(generation)
            llm_analysis = self.llm_analyze_patterns(gen_analysis)
        else:
            gen_analysis = {}
            llm_analysis = "æœªæŒ‡å®šå…·ä½“ä»£æ•°"
        
        evolution_analysis = self.analyze_evolution_trends()
        
        # ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“
        conn = sqlite3.connect(self.tracker.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO analyses 
            (experiment_id, generation, analysis_type, analysis_result, recommendations, timestamp)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (self.tracker.experiment_id, generation or -1, 'comprehensive', 
              json.dumps({
                  'generation_analysis': gen_analysis,
                  'evolution_analysis': evolution_analysis
              }), llm_analysis, datetime.now()))
        
        conn.commit()
        conn.close()
        
        return {
            'generation_analysis': gen_analysis,
            'evolution_analysis': evolution_analysis,
            'llm_insights': llm_analysis,
            'timestamp': datetime.now().isoformat()
        }


class PromptOptimizer:
    """æ™ºèƒ½Promptä¼˜åŒ–å™¨"""
    
    def __init__(self, tracker: EvolutionTracker, analyzer: StatisticalAnalyzer):
        self.tracker = tracker
        self.analyzer = analyzer
        self.llm_client = tracker.llm_client
    
    def generate_optimization_strategies(self, analysis_report: Dict[str, Any]) -> List[str]:
        """åŸºäºåˆ†ææŠ¥å‘Šç”Ÿæˆä¼˜åŒ–ç­–ç•¥"""
        evolution_data = analysis_report.get('evolution_analysis', {})
        llm_insights = analysis_report.get('llm_insights', '')
        
        strategy_prompt = f"""
åŸºäºä»¥ä¸‹promptè¿›åŒ–å®éªŒåˆ†æï¼Œè¯·æä¾›å…·ä½“çš„ä¼˜åŒ–ç­–ç•¥ï¼š

## è¿›åŒ–è¶‹åŠ¿åˆ†æ
- åˆ†æ•°æ”¹è¿›: {evolution_data.get('trends', {}).get('score_improvement', 0):.4f}
- æ”¶æ•›é€Ÿåº¦: {evolution_data.get('trends', {}).get('convergence_rate', 0):.4f}
- å¤šæ ·æ€§å˜åŒ–: {evolution_data.get('trends', {}).get('diversity_trend', 0):.4f}
- åœæ»æœŸé•¿åº¦: {evolution_data.get('trends', {}).get('stagnation_periods', 0)}

## LLMä¸“å®¶åˆ†æ
{llm_insights}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›5-8ä¸ªå…·ä½“çš„promptä¼˜åŒ–ç­–ç•¥ï¼Œæ¯ä¸ªç­–ç•¥åº”è¯¥åŒ…å«ï¼š
1. ç­–ç•¥åç§°
2. å…·ä½“å®æ–½æ–¹æ³•
3. é¢„æœŸæ•ˆæœ

æ ¼å¼è¦æ±‚ï¼š
- ç”¨ä¸­æ–‡å›ç­”
- æ¯ä¸ªç­–ç•¥ç”¨ç¼–å·åˆ—å‡º
- å…·ä½“å¯æ“ä½œ
"""
        
        try:
            strategies_text = sven_llm_query(strategy_prompt, self.llm_client, temperature=0.5)
            # ç®€å•è§£æç­–ç•¥ï¼ˆå®é™…å¯ä»¥æ›´å¤æ‚ï¼‰
            strategies = [line.strip() for line in strategies_text.split('\n') if line.strip() and any(char.isdigit() for char in line[:3])]
            return strategies
        except Exception as e:
            return [f"ç­–ç•¥ç”Ÿæˆå¤±è´¥: {str(e)}"]
    
    def optimize_prompt(self, base_prompt: str, strategy: str, target_metrics: Dict[str, float] = None) -> str:
        """æ ¹æ®ç­–ç•¥ä¼˜åŒ–å•ä¸ªprompt"""
        optimization_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„promptå·¥ç¨‹å¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¼˜åŒ–ç­–ç•¥æ”¹è¿›ç»™å®šçš„promptï¼š

## åŸå§‹Prompt
{base_prompt}

## ä¼˜åŒ–ç­–ç•¥
{strategy}

## ç›®æ ‡æŒ‡æ ‡ï¼ˆå¦‚æœæœ‰ï¼‰
{target_metrics or "æé«˜æ•´ä½“æ€§èƒ½"}

è¯·ç”Ÿæˆä¸€ä¸ªæ”¹è¿›åçš„promptï¼Œè¦æ±‚ï¼š
1. ä¿æŒåŸå§‹promptçš„æ ¸å¿ƒåŠŸèƒ½
2. åº”ç”¨æŒ‡å®šçš„ä¼˜åŒ–ç­–ç•¥
3. è¯­è¨€æ¸…æ™°ã€é€»è¾‘ä¸¥å¯†
4. é€‚åˆæ¼æ´æ£€æµ‹ä»»åŠ¡

åªè¿”å›ä¼˜åŒ–åçš„promptæ–‡æœ¬ï¼Œä¸è¦é¢å¤–è§£é‡Šã€‚
"""
        
        try:
            optimized_prompt = sven_llm_query(optimization_prompt, self.llm_client, temperature=0.3)
            return optimized_prompt.strip()
        except Exception as e:
            return base_prompt  # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œè¿”å›åŸprompt
    
    def batch_optimize_population(self, prompts: List[str], strategies: List[str], 
                                 generation: int) -> List[str]:
        """æ‰¹é‡ä¼˜åŒ–ç§ç¾¤ä¸­çš„prompts"""
        optimized_prompts = []
        
        print(f"ğŸ”§ Optimizing {len(prompts)} prompts with {len(strategies)} strategies...")
        
        for i, prompt in enumerate(prompts):
            # ä¸ºæ¯ä¸ªprompté€‰æ‹©ä¸åŒçš„ç­–ç•¥
            strategy = strategies[i % len(strategies)]
            
            try:
                optimized = self.optimize_prompt(prompt, strategy)
                optimized_prompts.append(optimized)
                print(f"  âœ… Optimized prompt {i+1}/{len(prompts)}")
            except Exception as e:
                print(f"  âŒ Failed to optimize prompt {i+1}: {e}")
                optimized_prompts.append(prompt)  # ä¿æŒåŸprompt
        
        return optimized_prompts


def create_evolution_tracker(output_dir: str, experiment_name: str = None) -> EvolutionTracker:
    """åˆ›å»ºè¿›åŒ–è·Ÿè¸ªå™¨çš„å·¥å‚å‡½æ•°"""
    return EvolutionTracker(output_dir, experiment_name)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª Testing Evolution Tracker...")
    
    tracker = create_evolution_tracker("./test_outputs", "test_experiment")
    tracker.start_experiment({"popsize": 10, "budget": 5, "dataset": "sven"})
    
    # æ¨¡æ‹Ÿä¸€äº›æ•°æ®
    import random
    for gen in range(3):
        scores = [random.uniform(0.7, 0.95) for _ in range(10)]
        tracker.log_generation(gen, scores)
        
        for i, score in enumerate(scores):
            prompt_text = f"Test prompt {gen}-{i} for vulnerability detection"
            detailed_scores = [score, score+0.1, score-0.05, score+0.02, score]
            tracker.log_prompt(gen, prompt_text, detailed_scores)
    
    # æµ‹è¯•åˆ†æ
    analyzer = StatisticalAnalyzer(tracker)
    report = analyzer.generate_comprehensive_report(generation=2)
    
    print("ğŸ“Š Analysis Report Generated!")
    print(f"Generation analysis: {len(report['generation_analysis'])} metrics")
    print(f"LLM insights length: {len(report['llm_insights'])} characters")