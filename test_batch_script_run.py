#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®æ”¹åçš„run_primevul_concurrent_optimized.pyçš„å®é™…è¿è¡Œ
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œå¿«é€Ÿæµ‹è¯•
"""

import sys
import os
import tempfile
import json
from pathlib import Path
import random

# æ·»åŠ srcè·¯å¾„
sys.path.insert(0, 'src')

def create_mock_data(temp_dir: Path):
    """åˆ›å»ºæ¨¡æ‹Ÿçš„Primevulæ•°æ®ç”¨äºæµ‹è¯•"""
    
    # åˆ›å»ºç®€å•çš„æ ·æœ¬æ•°æ®
    mock_samples = [
        {
            "func": "void vulnerable_func() {\n  char buf[10];\n  strcpy(buf, user_input);\n}",
            "target": "1",
            "project": "test_project", 
            "cwe": "CWE-120",
            "cve": "CVE-2023-TEST1"
        },
        {
            "func": "int safe_func(int x) {\n  if (x > 0) return x * 2;\n  return 0;\n}",
            "target": "0",
            "project": "test_project",
            "cwe": "",
            "cve": ""
        },
        {
            "func": "void sql_query(char* input) {\n  sprintf(query, \"SELECT * FROM users WHERE id=%s\", input);\n}",
            "target": "1", 
            "project": "test_project",
            "cwe": "CWE-89",
            "cve": "CVE-2023-TEST2"
        }
    ]
    
    # å†™å…¥å¼€å‘é›†
    dev_file = temp_dir / "dev.txt"
    with open(dev_file, 'w', encoding='utf-8') as f:
        for sample in mock_samples:
            line = f"{sample['func']}\t{sample['target']}\t{sample['project']}\t{sample['cwe']}\t{sample['cve']}\n"
            f.write(line)
    
    # å†™å…¥è®­ç»ƒé›†ï¼ˆæ›´å¤šæ•°æ®ç”¨äºè®­ç»ƒï¼‰
    train_file = temp_dir / "train.txt"
    with open(train_file, 'w', encoding='utf-8') as f:
        # é‡å¤æ ·æœ¬åˆ›å»ºæ›´å¤šè®­ç»ƒæ•°æ®
        for i in range(5):  # æ¯ä¸ªæ ·æœ¬é‡å¤5æ¬¡
            for sample in mock_samples:
                line = f"{sample['func']}\t{sample['target']}\t{sample['project']}\t{sample['cwe']}\t{sample['cve']}\n"
                f.write(line)
    
    print(f"âœ… åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®:")
    print(f"   å¼€å‘é›†: {dev_file} ({len(mock_samples)} æ ·æœ¬)")
    print(f"   è®­ç»ƒé›†: {train_file} ({len(mock_samples) * 5} æ ·æœ¬)")
    
    return str(temp_dir)


def create_test_config(output_dir: str):
    """åˆ›å»ºæµ‹è¯•é…ç½®"""
    config = {
        # å®éªŒæ ‡è¯†
        "experiment_id": "test_batch_processing",
        "experiment_name": "Test Batch Processing Integration",
        "timestamp": "20240101_120000",
        
        # æ•°æ®é…ç½®
        "dataset": "primevul",
        "sample_ratio": 0.01,
        "balanced_sampling": True,
        "shuffle_training_data": True,
        
        # ç®—æ³•é…ç½® - æœ€å°åŒ–ç”¨äºå¿«é€Ÿæµ‹è¯•
        "algorithm": "de",
        "population_size": 3,    # æœ€å°ç§ç¾¤
        "max_generations": 2,    # æœ€å°ä»£æ•°
        "mutation_rate": 0.15,
        "crossover_probability": 0.8,
        
        # æ ·æœ¬çº§åé¦ˆé…ç½®
        "sample_wise_feedback": True,
        "feedback_batch_size": 3,        # å°æ‰¹é‡
        "feedback_update_threshold": 0.1,
        "record_all_samples": True,
        
        # å¹¶å‘ä¼˜åŒ–é…ç½®  
        "max_concurrency": 4,        # å‡å°‘å¹¶å‘æ•°
        "force_async": False,        # ç¦ç”¨å¼‚æ­¥é¿å…å¤æ‚æ€§
        "batch_evaluation": True,
        
        # LLMæ‰¹å¤„ç†é…ç½®
        "llm_batch_size": 2,          # å°æ‰¹é‡æµ‹è¯•
        "enable_batch_processing": True, # å¯ç”¨æ‰¹å¤„ç†
        
        # LLMé…ç½®
        "llm_type": "gpt-3.5-turbo",
        "max_tokens": 50,       # å‡å°‘tokenæ•°
        "temperature": 0.7,
        
        # è¯„ä¼°é…ç½®
        "sample_size": None,
        "test_sample_size": None,
        
        # è¾“å‡ºé…ç½®
        "output_dir": output_dir,
        "save_population": True,
        "detailed_logging": True,
        
        # è¿½è¸ªé…ç½®
        "track_every_evaluation": True,
        "save_intermediate_results": True,
        "export_top_k": 3,
        "save_sample_results": True,

        # å¯ç”¨CWEå¤§ç±»æ¨¡å¼
        "use_cwe_major": True,
    }
    
    return config


def test_batch_integration():
    """æµ‹è¯•æ‰¹å¤„ç†é›†æˆ"""
    print("ğŸ§ª æµ‹è¯•æ‰¹å¤„ç†é›†æˆ...")
    
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)
        
        # 1. åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        mock_data_dir = create_mock_data(temp_path / "mock_data")
        
        # 2. åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = str(temp_path / "outputs")
        os.makedirs(output_dir, exist_ok=True)
        
        # 3. åˆ›å»ºæµ‹è¯•é…ç½®
        config = create_test_config(output_dir)
        
        print(f"\nğŸ“‹ æµ‹è¯•é…ç½®:")
        print(f"   ç§ç¾¤å¤§å°: {config['population_size']}")
        print(f"   æœ€å¤§ä»£æ•°: {config['max_generations']}")
        print(f"   LLMæ‰¹å¤„ç†: {config['enable_batch_processing']}")
        print(f"   LLMæ‰¹å¤§å°: {config['llm_batch_size']}")
        print(f"   åé¦ˆæ‰¹å¤§å°: {config['feedback_batch_size']}")
        
        try:
            # 4. å¯¼å…¥å¹¶è¿è¡Œå‡½æ•°ï¼ˆä½†ä¸çœŸæ­£æ‰§è¡ŒLLMè°ƒç”¨ï¼‰
            from run_primevul_concurrent_optimized import (
                evaluate_on_dataset, 
                sample_wise_feedback_training
            )
            from evoprompt.data.dataset import PrimevulDataset
            
            # 5. æµ‹è¯•æ•°æ®é›†åŠ è½½
            print(f"\nğŸ“Š æµ‹è¯•æ•°æ®é›†åŠ è½½...")
            dev_file = Path(mock_data_dir) / "dev.txt"
            dataset = PrimevulDataset(str(dev_file), "dev")
            samples = dataset.get_samples()
            print(f"   âœ… åŠ è½½ {len(samples)} ä¸ªå¼€å‘æ ·æœ¬")
            
            # 6. æµ‹è¯•é…ç½®å‚æ•°æå–
            print(f"\nâš™ï¸ æµ‹è¯•é…ç½®å‚æ•°æå–...")
            enable_batch = config.get('enable_batch_processing', False)
            batch_size = config.get('llm_batch_size', 8)
            
            if not enable_batch:
                print("   âŒ æ‰¹å¤„ç†æœªå¯ç”¨")
                return False
                
            if batch_size != 2:
                print(f"   âŒ æ‰¹å¤§å°é”™è¯¯: {batch_size} != 2")
                return False
                
            print(f"   âœ… æ‰¹å¤„ç†å‚æ•°æ­£ç¡®: enable={enable_batch}, batch_size={batch_size}")
            
            # 7. æµ‹è¯•æ ·æœ¬å¤„ç†é€»è¾‘ï¼ˆä¸è°ƒç”¨çœŸå®LLMï¼‰
            print(f"\nğŸ”„ æµ‹è¯•æ ·æœ¬å¤„ç†é€»è¾‘...")
            
            # åˆ›å»ºæ¨¡æ‹Ÿçš„æ‰¹å¤„ç†æŸ¥è¯¢
            test_prompt = "Analyze this code for vulnerabilities: {input}"
            batch_queries = []
            batch_samples = []
            
            for i, sample in enumerate(samples):
                code = sample.input_text
                query = test_prompt.format(input=code[:100])  # æˆªå–å‰100å­—ç¬¦
                batch_queries.append(query)
                batch_samples.append(sample)
            
            print(f"   âœ… å‡†å¤‡äº† {len(batch_queries)} ä¸ªæ‰¹å¤„ç†æŸ¥è¯¢")
            
            # 8. éªŒè¯æ‰¹å¤„ç†åˆ†ç»„é€»è¾‘
            expected_batches = (len(batch_queries) + batch_size - 1) // batch_size
            print(f"   âœ… é¢„æœŸæ‰¹æ¬¡æ•°: {expected_batches} (æ€»æŸ¥è¯¢: {len(batch_queries)}, æ‰¹å¤§å°: {batch_size})")
            
            return True
            
        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    """è¿è¡Œé›†æˆæµ‹è¯•"""
    print("=== æ‰¹å¤„ç†é›†æˆæµ‹è¯• ===")
    print("æµ‹è¯•ä¿®æ”¹åçš„run_primevul_concurrent_optimized.py")
    print()
    
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    
    try:
        result = test_batch_integration()
        
        print(f"\n=== æµ‹è¯•ç»“æœ ===")
        if result:
            print("ğŸ‰ æ‰¹å¤„ç†é›†æˆæµ‹è¯•é€šè¿‡ï¼")
            print("âœ… run_primevul_concurrent_optimized.py å·²æˆåŠŸé›†æˆ batch_size=8 åŠŸèƒ½")
            print()
            print("ğŸ“ ä¸»è¦æ”¹è¿›:")
            print("   â€¢ æ·»åŠ äº† llm_batch_size å’Œ enable_batch_processing é…ç½®")
            print("   â€¢ evaluate_on_dataset æ”¯æŒæ‰¹å¤„ç†è¯„ä¼°")  
            print("   â€¢ sample_wise_feedback_training æ”¯æŒæ‰¹é‡é¢„æµ‹å’Œæ”¹è¿›")
            print("   â€¢ è‡ªåŠ¨å›é€€åˆ°å•ä¸ªå¤„ç†æ¨¡å¼ï¼ˆå‡ºé”™æ—¶ï¼‰")
            print("   â€¢ ä¿æŒä¸åŸæœ‰åŠŸèƒ½çš„å®Œå…¨å…¼å®¹")
            return 0
        else:
            print("âŒ æ‰¹å¤„ç†é›†æˆæµ‹è¯•å¤±è´¥")
            return 1
            
    except Exception as e:
        print(f"ğŸ’¥ é›†æˆæµ‹è¯•å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())