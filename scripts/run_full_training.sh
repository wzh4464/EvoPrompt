#!/bin/bash

# å…¨é‡è®­ç»ƒè„šæœ¬ - 5ä»£è¿›åŒ–ï¼Œæ‰€æœ‰æ•°æ®
# é¢„è®¡æ—¶é—´ï¼š2-4å°æ—¶

echo "ğŸš€ å¯åŠ¨å…¨é‡è®­ç»ƒ"
echo "======================================================================"
echo ""
echo "é…ç½®:"
echo "  - è¿›åŒ–ä»£æ•°: 5 generations"
echo "  - ç§ç¾¤å¤§å°: 5"
echo "  - è¯„ä¼°æ ·æœ¬: æ‰€æœ‰æ•°æ®ï¼ˆä¸é™åˆ¶ï¼‰"
echo "  - RAG: å¯ç”¨"
echo "  - Scale: å¯ç”¨"
echo "  - çŸ¥è¯†åº“: ä»è®­ç»ƒé›†è‡ªåŠ¨æ„å»º"
echo ""
echo "é¢„è®¡æ—¶é—´: 2-4å°æ—¶"
echo "======================================================================"
echo ""

# ä½¿ç”¨unbuffered Pythonè¾“å‡ºä»¥ä¾¿å®æ—¶æŸ¥çœ‹è¿›åº¦
PYTHONUNBUFFERED=1 uv run python scripts/train_three_layer.py \
    --train \
    --use-rag \
    --use-scale \
    --kb-from-dataset \
    --kb-samples-per-category 5 \
    --population-size 5 \
    --max-generations 5 \
    --eval-samples 1000 \
    --batch-size 20 \
    --elite-size 2 \
    --mutation-rate 0.3 \
    --meta-improve-interval 2 \
    --meta-improve-count 3 \
    --output-dir ./outputs/full_training_5gen \
    2>&1 | tee training_log_$(date +%Y%m%d_%H%M%S).txt

echo ""
echo "======================================================================"
echo "âœ… è®­ç»ƒå®Œæˆï¼"
echo "ç»“æœä¿å­˜åœ¨: ./outputs/full_training_5gen/"
echo "æ—¥å¿—æ–‡ä»¶: training_log_*.txt"
echo "======================================================================"
