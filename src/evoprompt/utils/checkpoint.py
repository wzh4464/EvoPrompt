"""
Checkpoint ç®¡ç†æ¨¡å— - å¤„ç†å®éªŒæ–­ç‚¹ä¿å­˜å’Œæ¢å¤

åŠŸèƒ½:
1. è‡ªåŠ¨ä¿å­˜ checkpoint (æ¯ä¸ª batchã€æ¯ä»£è¿›åŒ–å)
2. ä» checkpoint æ¢å¤å®éªŒ
3. API å¤±è´¥é‡è¯•æœºåˆ¶
4. å¤šçº§å¤‡ä»½ç­–ç•¥
"""

import json
import shutil
import time
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime
import pickle


class CheckpointManager:
    """Checkpoint ç®¡ç†å™¨"""

    def __init__(self, exp_dir: Path, auto_save: bool = True):
        """
        Args:
            exp_dir: å®éªŒç›®å½•
            auto_save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜ checkpoint
        """
        self.exp_dir = Path(exp_dir)
        self.checkpoint_dir = self.exp_dir / "checkpoints"
        self.checkpoint_dir.mkdir(exist_ok=True, parents=True)
        self.auto_save = auto_save

        # Checkpoint æ–‡ä»¶
        self.latest_checkpoint = self.checkpoint_dir / "latest.json"
        self.backup_checkpoint = self.checkpoint_dir / "backup.json"
        self.state_file = self.checkpoint_dir / "state.pkl"

        print(f"âœ… Checkpoint ç®¡ç†å™¨åˆå§‹åŒ–")
        print(f"   Checkpoint ç›®å½•: {self.checkpoint_dir}")

    def save_checkpoint(
        self,
        generation: int,
        batch_idx: int,
        population: List[Any],
        best_results: List[Dict[str, Any]],
        metadata: Optional[Dict[str, Any]] = None
    ) -> Path:
        """
        ä¿å­˜ checkpoint

        Args:
            generation: å½“å‰ä»£æ•°
            batch_idx: å½“å‰ batch ç´¢å¼•
            population: ç§ç¾¤
            best_results: æœ€ä½³ç»“æœå†å²
            metadata: é¢å¤–å…ƒæ•°æ®

        Returns:
            checkpoint æ–‡ä»¶è·¯å¾„
        """
        checkpoint_data = {
            "timestamp": datetime.now().isoformat(),
            "generation": generation,
            "batch_idx": batch_idx,
            "num_individuals": len(population),
            "best_fitness": population[0][0].fitness if population else 0.0,
            "metadata": metadata or {},
        }

        # ä¿å­˜è½»é‡çº§ JSON checkpoint (ç”¨äºå¿«é€Ÿæ¢å¤)
        try:
            # å¤‡ä»½å½“å‰ latest åˆ° backup
            if self.latest_checkpoint.exists():
                shutil.copy(self.latest_checkpoint, self.backup_checkpoint)

            with open(self.latest_checkpoint, "w", encoding="utf-8") as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)

            # ä¿å­˜å®Œæ•´çŠ¶æ€ (pickle)
            state = {
                "generation": generation,
                "batch_idx": batch_idx,
                "population": population,
                "best_results": best_results,
                "metadata": metadata,
            }

            with open(self.state_file, "wb") as f:
                pickle.dump(state, f)

            # ä¿å­˜å¸¦æ—¶é—´æˆ³çš„å†å² checkpoint
            history_checkpoint = self.checkpoint_dir / f"gen{generation}_batch{batch_idx}.json"
            with open(history_checkpoint, "w", encoding="utf-8") as f:
                json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)

            return self.latest_checkpoint

        except Exception as e:
            print(f"âš ï¸ Checkpoint ä¿å­˜å¤±è´¥: {e}")
            return None

    def load_checkpoint(self) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½æœ€æ–°çš„ checkpoint

        Returns:
            checkpoint æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        # é¦–å…ˆå°è¯•åŠ è½½ latest
        if self.latest_checkpoint.exists():
            try:
                with open(self.latest_checkpoint, "r", encoding="utf-8") as f:
                    checkpoint = json.load(f)
                print(f"âœ… ä» checkpoint æ¢å¤:")
                print(f"   ä»£æ•°: {checkpoint['generation']}")
                print(f"   Batch: {checkpoint['batch_idx']}")
                print(f"   æœ€ä½³é€‚åº”åº¦: {checkpoint['best_fitness']:.4f}")
                return checkpoint
            except Exception as e:
                print(f"âš ï¸ Latest checkpoint åŠ è½½å¤±è´¥: {e}")

        # å¦‚æœ latest å¤±è´¥ï¼Œå°è¯• backup
        if self.backup_checkpoint.exists():
            try:
                with open(self.backup_checkpoint, "r", encoding="utf-8") as f:
                    checkpoint = json.load(f)
                print(f"âœ… ä» backup checkpoint æ¢å¤:")
                print(f"   ä»£æ•°: {checkpoint['generation']}")
                print(f"   Batch: {checkpoint['batch_idx']}")
                return checkpoint
            except Exception as e:
                print(f"âš ï¸ Backup checkpoint åŠ è½½å¤±è´¥: {e}")

        return None

    def load_full_state(self) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½å®Œæ•´çŠ¶æ€ (åŒ…æ‹¬ç§ç¾¤)

        Returns:
            å®Œæ•´çŠ¶æ€ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        if not self.state_file.exists():
            return None

        try:
            with open(self.state_file, "rb") as f:
                state = pickle.load(f)
            print(f"âœ… å®Œæ•´çŠ¶æ€æ¢å¤æˆåŠŸ")
            return state
        except Exception as e:
            print(f"âš ï¸ å®Œæ•´çŠ¶æ€åŠ è½½å¤±è´¥: {e}")
            return None

    def has_checkpoint(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨ checkpoint"""
        return self.latest_checkpoint.exists() or self.backup_checkpoint.exists()

    def list_checkpoints(self) -> List[Path]:
        """åˆ—å‡ºæ‰€æœ‰å†å² checkpoint"""
        return sorted(self.checkpoint_dir.glob("gen*_batch*.json"))

    def cleanup_old_checkpoints(self, keep_last_n: int = 10):
        """æ¸…ç†æ—§çš„ checkpointï¼Œä¿ç•™æœ€è¿‘ N ä¸ª"""
        checkpoints = self.list_checkpoints()
        if len(checkpoints) > keep_last_n:
            for ckpt in checkpoints[:-keep_last_n]:
                try:
                    ckpt.unlink()
                    print(f"  ğŸ—‘ï¸ æ¸…ç†æ—§ checkpoint: {ckpt.name}")
                except Exception as e:
                    print(f"  âš ï¸ æ¸…ç†å¤±è´¥ {ckpt.name}: {e}")


class RetryManager:
    """API è°ƒç”¨é‡è¯•ç®¡ç†å™¨"""

    def __init__(
        self,
        max_retries: int = 3,
        base_delay: float = 1.0,
        exponential_backoff: bool = True
    ):
        """
        Args:
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            exponential_backoff: æ˜¯å¦ä½¿ç”¨æŒ‡æ•°é€€é¿
        """
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.exponential_backoff = exponential_backoff
        self.retry_count = 0
        self.success_count = 0
        self.failure_count = 0

    def retry_with_backoff(self, func, *args, **kwargs):
        """
        ä½¿ç”¨é‡è¯•å’Œé€€é¿ç­–ç•¥æ‰§è¡Œå‡½æ•°

        Args:
            func: è¦æ‰§è¡Œçš„å‡½æ•°
            *args, **kwargs: å‡½æ•°å‚æ•°

        Returns:
            å‡½æ•°è¿”å›å€¼

        Raises:
            æœ€åä¸€æ¬¡å¤±è´¥çš„å¼‚å¸¸
        """
        last_exception = None

        for attempt in range(self.max_retries):
            try:
                result = func(*args, **kwargs)
                self.success_count += 1
                self.retry_count = 0  # é‡ç½®é‡è¯•è®¡æ•°
                return result

            except Exception as e:
                last_exception = e
                self.retry_count += 1
                self.failure_count += 1

                if attempt < self.max_retries - 1:
                    # è®¡ç®—å»¶è¿Ÿæ—¶é—´
                    if self.exponential_backoff:
                        delay = self.base_delay * (2 ** attempt)
                    else:
                        delay = self.base_delay

                    print(f"      âš ï¸ API è°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                    print(f"      â³ ç­‰å¾… {delay:.1f}ç§’ åé‡è¯•...")
                    time.sleep(delay)
                else:
                    print(f"      âŒ API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")

        raise last_exception

    def get_stats(self) -> Dict[str, int]:
        """è·å–é‡è¯•ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "success_count": self.success_count,
            "failure_count": self.failure_count,
            "current_retry_count": self.retry_count,
        }


class BatchCheckpointer:
    """Batch çº§åˆ«çš„ checkpoint ç®¡ç†"""

    def __init__(self, checkpoint_dir: Path, batch_size: int):
        """
        Args:
            checkpoint_dir: Checkpoint ç›®å½•
            batch_size: Batch å¤§å°
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.batch_dir = self.checkpoint_dir / "batches"
        self.batch_dir.mkdir(exist_ok=True, parents=True)
        self.batch_size = batch_size

    def save_batch_result(
        self,
        generation: int,
        batch_idx: int,
        predictions: List[str],
        ground_truths: List[str],
        batch_analysis: Dict[str, Any],
        prompt: str
    ):
        """
        ä¿å­˜å•ä¸ª batch çš„ç»“æœ

        Args:
            generation: ä»£æ•°
            batch_idx: Batch ç´¢å¼•
            predictions: é¢„æµ‹ç»“æœ
            ground_truths: çœŸå®æ ‡ç­¾
            batch_analysis: Batch åˆ†æç»“æœ
            prompt: ä½¿ç”¨çš„ prompt
        """
        batch_file = self.batch_dir / f"gen{generation}_batch{batch_idx}.json"

        batch_data = {
            "generation": generation,
            "batch_idx": batch_idx,
            "timestamp": datetime.now().isoformat(),
            "predictions": predictions,
            "ground_truths": ground_truths,
            "analysis": batch_analysis,
            "prompt": prompt,
        }

        try:
            with open(batch_file, "w", encoding="utf-8") as f:
                json.dump(batch_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"      âš ï¸ Batch checkpoint ä¿å­˜å¤±è´¥: {e}")

    def load_batch_result(self, generation: int, batch_idx: int) -> Optional[Dict[str, Any]]:
        """
        åŠ è½½å•ä¸ª batch çš„ç»“æœ

        Args:
            generation: ä»£æ•°
            batch_idx: Batch ç´¢å¼•

        Returns:
            Batch æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å› None
        """
        batch_file = self.batch_dir / f"gen{generation}_batch{batch_idx}.json"

        if not batch_file.exists():
            return None

        try:
            with open(batch_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"      âš ï¸ Batch checkpoint åŠ è½½å¤±è´¥: {e}")
            return None

    def has_batch(self, generation: int, batch_idx: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦å­˜åœ¨ batch checkpoint"""
        batch_file = self.batch_dir / f"gen{generation}_batch{batch_idx}.json"
        return batch_file.exists()

    def get_completed_batches(self, generation: int) -> List[int]:
        """è·å–å·²å®Œæˆçš„ batch ç´¢å¼•åˆ—è¡¨"""
        pattern = f"gen{generation}_batch*.json"
        batch_files = self.batch_dir.glob(pattern)

        completed = []
        for batch_file in batch_files:
            # ä»æ–‡ä»¶åæå– batch_idx
            try:
                batch_idx = int(batch_file.stem.split("_batch")[1])
                completed.append(batch_idx)
            except (IndexError, ValueError):
                continue

        return sorted(completed)


class ExperimentRecovery:
    """å®éªŒæ¢å¤ç®¡ç†å™¨"""

    def __init__(self, exp_dir: Path):
        """
        Args:
            exp_dir: å®éªŒç›®å½•
        """
        self.exp_dir = Path(exp_dir)
        self.checkpoint_manager = CheckpointManager(exp_dir)
        self.recovery_log = self.exp_dir / "recovery.log"

    def can_recover(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥æ¢å¤å®éªŒ"""
        return self.checkpoint_manager.has_checkpoint()

    def recover_experiment(self) -> Optional[Dict[str, Any]]:
        """
        æ¢å¤å®éªŒ

        Returns:
            æ¢å¤çš„çŠ¶æ€ï¼Œå¦‚æœæ— æ³•æ¢å¤è¿”å› None
        """
        if not self.can_recover():
            print("âš ï¸ æœªæ‰¾åˆ°å¯æ¢å¤çš„ checkpoint")
            return None

        # å°è¯•åŠ è½½å®Œæ•´çŠ¶æ€
        state = self.checkpoint_manager.load_full_state()

        if state:
            self._log_recovery(state)
            return state

        # å¦‚æœå®Œæ•´çŠ¶æ€åŠ è½½å¤±è´¥ï¼Œè‡³å°‘åŠ è½½åŸºç¡€ä¿¡æ¯
        checkpoint = self.checkpoint_manager.load_checkpoint()
        if checkpoint:
            self._log_recovery(checkpoint)
            return {"checkpoint": checkpoint, "full_state": False}

        return None

    def _log_recovery(self, state: Dict[str, Any]):
        """è®°å½•æ¢å¤æ—¥å¿—"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "recovered_state": {
                "generation": state.get("generation"),
                "batch_idx": state.get("batch_idx"),
            }
        }

        try:
            with open(self.recovery_log, "a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
        except Exception as e:
            print(f"âš ï¸ æ¢å¤æ—¥å¿—å†™å…¥å¤±è´¥: {e}")


def with_retry(max_retries: int = 3, base_delay: float = 1.0):
    """
    è£…é¥°å™¨ï¼šä¸ºå‡½æ•°æ·»åŠ é‡è¯•æœºåˆ¶

    Args:
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´

    Example:
        @with_retry(max_retries=3, base_delay=2.0)
        def api_call():
            return llm_client.generate(prompt)
    """
    def decorator(func):
        def wrapper(*args, **kwargs):
            retry_manager = RetryManager(max_retries, base_delay)
            return retry_manager.retry_with_backoff(func, *args, **kwargs)
        return wrapper
    return decorator
