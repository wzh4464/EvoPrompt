# è¯„ä¼°æŒ‡æ ‡åŠŸèƒ½æ€»ç»“

## ğŸ¯ æ ¸å¿ƒæ”¹è¿›

### 1. æ–°å¢å¤šåˆ†ç±»è¯„ä¼°æ¨¡å—

**æ–‡ä»¶**: `src/evoprompt/evaluators/multiclass_metrics.py`

**åŠŸèƒ½**:
- âœ… `ClassMetrics`: å•ä¸ªç±»åˆ«çš„TP/FP/TN/FNå’ŒP/R/F1
- âœ… `MultiClassMetrics`: å¤šåˆ†ç±»åœºæ™¯çš„å®Œæ•´æŒ‡æ ‡
- âœ… **Macro-F1**: æ‰€æœ‰ç±»åˆ«åŒç­‰é‡è¦ (æ¨èç”¨äºæ¼æ´æ£€æµ‹)
- âœ… **Weighted-F1**: æŒ‰æ ·æœ¬æ•°åŠ æƒ
- âœ… **Micro-F1**: å…¨å±€è®¡ç®— (ç­‰åŒäºaccuracy)
- âœ… Per-classè¯¦ç»†æŒ‡æ ‡
- âœ… æ··æ·†çŸ©é˜µ
- âœ… åˆ†ç±»æŠ¥å‘Š

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from evoprompt.evaluators.multiclass_metrics import MultiClassMetrics

metrics = MultiClassMetrics()
for pred, actual in predictions:
    metrics.add_prediction(pred, actual)

# è·å–ä¸‰ç§F1
macro_f1 = metrics.compute_macro_f1()      # â­ æ¨è
weighted_f1 = metrics.compute_weighted_f1()
micro_f1 = metrics.compute_micro_f1()

# æ‰“å°å®Œæ•´æŠ¥å‘Š
metrics.print_report()
```

---

### 2. æ›´æ–°ä¸‰å±‚æ£€æµ‹è¯„ä¼°å™¨

**æ–‡ä»¶**: `src/evoprompt/detectors/three_layer_detector.py`

**æ”¹è¿›**:
- âœ… é›†æˆ`MultiClassMetrics`
- âœ… æ¯å±‚éƒ½è®¡ç®—Macro/Weighted/Micro F1
- âœ… Per-classè¯¦ç»†æŒ‡æ ‡
- âœ… `verbose=True`æ¨¡å¼æ‰“å°è¯¦ç»†æŠ¥å‘Š

**è¾“å‡ºæ ¼å¼**:
```json
{
  "layer1": {
    "accuracy": 0.80,
    "macro_f1": 0.65,       // â­ æ¨èå…³æ³¨
    "weighted_f1": 0.75,
    "micro_f1": 0.80,
    "macro_precision": 0.63,
    "macro_recall": 0.67
  },
  "layer1_per_class": {
    "Memory": {
      "precision": 0.85,
      "recall": 0.80,
      "f1_score": 0.825,
      "support": 50
    },
    ...
  }
}
```

---

### 3. æ›´æ–°ä¸»è®­ç»ƒè„šæœ¬

**æ–‡ä»¶**: `scripts/train_three_layer.py`

**æ”¹è¿›**:
- âœ… ä½¿ç”¨`verbose=True`è¯„ä¼°
- âœ… è‡ªåŠ¨æ‰“å°è¯¦ç»†çš„Macro/Weighted/Micro F1
- âœ… æ ‡æ³¨æ¨èæŒ‡æ ‡ â­

**ç¤ºä¾‹è¾“å‡º**:
```
======================================================================
EVALUATION RESULTS
======================================================================

Total Samples: 50
Full Path Accuracy: 0.4200

----------------------------------------------------------------------
Layer 1 (Major Category)
----------------------------------------------------------------------
  Accuracy:        0.8000
  Macro-F1:        0.6500 â­ (æ¨è)
  Weighted-F1:     0.7500
  Micro-F1:        0.8000
  Macro-Precision: 0.6300
  Macro-Recall:    0.6700

======================================================================
ğŸ’¡ æ¨èå…³æ³¨æŒ‡æ ‡: Macro-F1
   åŸå› : æ¼æ´æ£€æµ‹ä¸­ç±»åˆ«ä¸å¹³è¡¡ï¼ŒMacro-F1ç¡®ä¿æ‰€æœ‰ç±»åˆ«éƒ½è¢«é‡è§†
======================================================================
```

---

### 4. æ–°å¢æ¼”ç¤ºè„šæœ¬

**æ–‡ä»¶**: `scripts/demo_f1_metrics.py`

**åŠŸèƒ½**:
- âœ… åœºæ™¯1: å¹³è¡¡æ•°æ®é›†
- âœ… åœºæ™¯2: ä¸å¹³è¡¡æ•°æ®é›† - å¤šæ•°ç±»å¥½
- âœ… åœºæ™¯3: ä¸å¹³è¡¡æ•°æ®é›† - å°‘æ•°ç±»å¥½
- âœ… åœºæ™¯4: ä¸‰å±‚æ£€æµ‹å®é™…åº”ç”¨
- âœ… å¯¹æ¯”åˆ†æä¸‰ç§F1çš„å·®å¼‚

**è¿è¡Œ**:
```bash
uv run python scripts/demo_f1_metrics.py
```

---

### 5. æ–°å¢æ–‡æ¡£

**æ–‡ä»¶**: `METRICS_GUIDE.md`

**å†…å®¹**:
- âœ… Macro/Weighted/Micro F1çš„å®šä¹‰å’Œå…¬å¼
- âœ… ä¸ºä»€ä¹ˆåœ¨æ¼æ´æ£€æµ‹ä¸­å¿…é¡»ä½¿ç”¨Macro-F1
- âœ… å®é™…æ¡ˆä¾‹å¯¹æ¯”
- âœ… EvoPromptä¸­çš„å®ç°
- âœ… è®ºæ–‡æŠ¥å‘Šå»ºè®®
- âœ… ç›¸å…³æ–‡çŒ®

---

## ğŸ“Š ä¸‰ç§F1å¯¹æ¯”

### åœºæ™¯ï¼šä¸å¹³è¡¡æ•°æ®é›†

```
Benign (å®‰å…¨ä»£ç ):     900 samples, F1 = 0.95
Vulnerable (æ¼æ´ä»£ç ): 100 samples, F1 = 0.30
```

### è®¡ç®—ç»“æœ

| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |
|------|-----|------|
| **Macro-F1** | **0.625** | âœ… æ­ç¤ºæ¨¡å‹åœ¨Vulnerableä¸Šçš„å·®è¡¨ç° |
| Weighted-F1 | 0.885 | âš ï¸ è¢«å¤šæ•°ç±»ä¸»å¯¼ï¼Œäº§ç”Ÿè¯¯å¯¼æ€§é«˜åˆ† |
| Micro-F1 | 0.840 | â„¹ï¸ ç­‰åŒäºå‡†ç¡®ç‡ |

### ç»“è®º

åœ¨æ¼æ´æ£€æµ‹ä¸­**å¿…é¡»ä½¿ç”¨Macro-F1**ï¼Œå› ä¸ºï¼š
1. æ•°æ®ä¸¥é‡ä¸å¹³è¡¡ (å®‰å…¨ä»£ç  >> æ¼æ´ä»£ç )
2. å°‘æ•°ç±»ï¼ˆæ¼æ´ï¼‰åŒæ ·é‡è¦ï¼Œä¸èƒ½å¿½è§†
3. Weighted-F1ä¼šæ©ç›–å°‘æ•°ç±»çš„å¤±è´¥

---

## ğŸš€ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

```bash
# 1. æŸ¥çœ‹F1æŒ‡æ ‡æ¼”ç¤º
uv run python scripts/demo_f1_metrics.py

# 2. è¿è¡Œè¯„ä¼° (è‡ªåŠ¨æ‰“å°Macro/Weighted/Micro F1)
uv run python scripts/train_three_layer.py --eval-samples 50
```

### åœ¨ä»£ç ä¸­ä½¿ç”¨

```python
from evoprompt.detectors.three_layer_detector import ThreeLayerDetector, ThreeLayerEvaluator
from evoprompt.data.dataset import PrimevulDataset

# åˆ›å»ºæ£€æµ‹å™¨
detector = ThreeLayerDetector(...)

# åˆ›å»ºè¯„ä¼°å™¨
dataset = PrimevulDataset("data/primevul_1percent_sample/dev.txt", "dev")
evaluator = ThreeLayerEvaluator(detector, dataset)

# è¯„ä¼° (verbose=Trueæ‰“å°è¯¦ç»†æŒ‡æ ‡)
metrics = evaluator.evaluate(sample_size=50, verbose=True)

# è·å–Macro-F1
layer1_macro_f1 = metrics["layer1"]["macro_f1"]
layer2_macro_f1 = metrics["layer2"]["macro_f1"]
layer3_macro_f1 = metrics["layer3"]["macro_f1"]
```

---

## ğŸ“ è®ºæ–‡æŠ¥å‘Šå»ºè®®

### è¡¨æ ¼æ ¼å¼

| é…ç½® | Layer 1<br>Macro-F1 | Layer 2<br>Macro-F1 | Layer 3<br>Macro-F1 | Full Path<br>Accuracy |
|------|---------------------|---------------------|---------------------|-----------------------|
| åŸºçº¿ | 0.65 | 0.55 | 0.45 | 0.30 |
| + RAG | 0.72 (+11%) | 0.63 (+15%) | 0.52 (+16%) | 0.40 (+33%) |
| + è®­ç»ƒ | 0.80 (+23%) | 0.70 (+27%) | 0.60 (+33%) | 0.45 (+50%) |
| RAG+è®­ç»ƒ | 0.88 (+35%) | 0.78 (+42%) | 0.68 (+51%) | 0.55 (+83%) |

### è¯´æ˜æ–‡æœ¬

```
æˆ‘ä»¬ä½¿ç”¨Macro-F1ä½œä¸ºä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼Œå› ä¸ºæ¼æ´æ£€æµ‹æ•°æ®é›†å­˜åœ¨ä¸¥é‡çš„
ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼ˆå®‰å…¨ä»£ç å æ¯” > 90%ï¼‰ã€‚Macro-F1èƒ½å¤Ÿç¡®ä¿æ¨¡å‹åœ¨
æ‰€æœ‰CWEç±»åˆ«ï¼ˆåŒ…æ‹¬ç½•è§ä½†å…³é”®çš„å°‘æ•°ç±»ï¼‰ä¸Šéƒ½ä¿æŒè‰¯å¥½æ€§èƒ½ï¼Œé¿å…è¢«
å¤šæ•°ç±»ä¸»å¯¼çš„è¯¯å¯¼æ€§é«˜åˆ†ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬ä¹ŸæŠ¥å‘Šäº†Weighted-F1å’ŒAccuracyä½œä¸ºè¾…åŠ©å‚è€ƒæŒ‡æ ‡ã€‚
è¯¦ç»†çš„Per-class F1åˆ†æ•°è§é™„å½•è¡¨Xã€‚
```

---

## ğŸ”— ç›¸å…³æ–‡ä»¶

### ä»£ç 

- `src/evoprompt/evaluators/multiclass_metrics.py` - å¤šåˆ†ç±»æŒ‡æ ‡æ¨¡å— â­
- `src/evoprompt/detectors/three_layer_detector.py` - æ›´æ–°çš„è¯„ä¼°å™¨
- `src/evoprompt/evaluators/__init__.py` - å¯¼å‡ºæ¨¡å—

### è„šæœ¬

- `scripts/train_three_layer.py` - ä¸»è„šæœ¬ (verboseè¯„ä¼°)
- `scripts/demo_f1_metrics.py` - F1æŒ‡æ ‡æ¼”ç¤º â­

### æ–‡æ¡£

- `METRICS_GUIDE.md` - è¯¦ç»†æŒ‡æ ‡æŒ‡å— â­
- `START_HERE.md` - æ›´æ–°çš„å…¥å£æ–‡æ¡£
- `README_INDEX.md` - æ›´æ–°çš„æ–‡æ¡£ç´¢å¼•

---

## ğŸ’¡ å…³é”®è¦ç‚¹

1. **Macro-F1 æ˜¯æ¼æ´æ£€æµ‹çš„é¦–é€‰æŒ‡æ ‡** â­
   - æ‰€æœ‰ç±»åˆ«åŒç­‰é‡è¦
   - é¿å…è¢«å¤šæ•°ç±»è¯¯å¯¼

2. **ç³»ç»Ÿè‡ªåŠ¨è®¡ç®—ä¸‰ç§F1**
   - æä¾›å®Œæ•´çš„æ€§èƒ½è§†å›¾
   - ä¾¿äºè®ºæ–‡æŠ¥å‘Š

3. **Per-classæŒ‡æ ‡å¸®åŠ©å®šä½é—®é¢˜**
   - æ‰¾å‡ºè¡¨ç°å·®çš„ç±»åˆ«
   - é’ˆå¯¹æ€§ä¼˜åŒ–

4. **è¯¦ç»†çš„å¯è§†åŒ–æŠ¥å‘Š**
   - verbose=Trueæ¨¡å¼
   - æ¸…æ™°æ ‡æ³¨æ¨èæŒ‡æ ‡

---

## ğŸ“ å­¦ä¹ èµ„æº

### è¿è¡Œæ¼”ç¤º

```bash
# F1æŒ‡æ ‡å¯¹æ¯”æ¼”ç¤º (æ¨è!)
uv run python scripts/demo_f1_metrics.py
```

### é˜…è¯»æ–‡æ¡£

1. `METRICS_GUIDE.md` - å®Œæ•´çš„æŒ‡æ ‡æŒ‡å—
2. `QUICKSTART.md` - å¿«é€Ÿå¼€å§‹
3. `THREE_LAYER_README.md` - ä¸‰å±‚æ£€æµ‹è¯¦è§£

### å®é™…è¿è¡Œ

```bash
# è¯„ä¼°å¹¶æŸ¥çœ‹è¯¦ç»†æŒ‡æ ‡
uv run python scripts/train_three_layer.py --use-rag --eval-samples 50
```

---

## âœ… æ€»ç»“

### æ–°å¢åŠŸèƒ½

1. âœ… å®Œæ•´çš„å¤šåˆ†ç±»è¯„ä¼°æ¨¡å—
2. âœ… Macro/Weighted/Micro F1è‡ªåŠ¨è®¡ç®—
3. âœ… Per-classè¯¦ç»†æŒ‡æ ‡
4. âœ… å¯è§†åŒ–æŠ¥å‘Š
5. âœ… F1å¯¹æ¯”æ¼”ç¤º
6. âœ… è¯¦ç»†æ–‡æ¡£

### ä½¿ç”¨å»ºè®®

- **ä¸»è¦æŒ‡æ ‡**: Macro-F1 â­
- **è¾…åŠ©æŒ‡æ ‡**: Weighted-F1, Accuracy
- **è¯¦ç»†åˆ†æ**: Per-class F1

### è®ºæ–‡æŠ¥å‘Š

- æŠ¥å‘Šæ‰€æœ‰ä¸‰ç§F1
- å¼ºè°ƒMacro-F1
- è¯´æ˜é€‰æ‹©åŸå› 

---

**å¼€å§‹ä½¿ç”¨**: è¿è¡Œ `uv run python scripts/demo_f1_metrics.py` æŸ¥çœ‹æ¼”ç¤ºï¼
