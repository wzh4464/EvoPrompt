#!/usr/bin/env python3
"""
éªŒè¯run_primevul_concurrent_optimized.pyé»˜è®¤ä½¿ç”¨concurrent=True
"""

import sys
import inspect
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥scriptsæ¨¡å—
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def test_default_concurrent_config():
    """æµ‹è¯•é»˜è®¤é…ç½®æ˜¯å¦å¯ç”¨å¹¶å‘"""
    print("ğŸ”§ æµ‹è¯•é»˜è®¤å¹¶å‘é…ç½®...")

    from scripts.run_primevul_concurrent_optimized import create_optimized_config

    config = create_optimized_config()

    # æ£€æŸ¥å…³é”®é…ç½®
    required_config = {
        "enable_batch_processing": True,
        "llm_batch_size": 8,
        "enable_concurrent": True,  # è¿™æ˜¯å…³é”®
    }

    print("ğŸ“‹ æ£€æŸ¥é…ç½®é¡¹:")
    all_correct = True

    for key, expected_value in required_config.items():
        actual_value = config.get(key)
        status = "âœ…" if actual_value == expected_value else "âŒ"
        print(f"   {status} {key}: {actual_value} (æœŸæœ›: {expected_value})")
        if actual_value != expected_value:
            all_correct = False

    return all_correct


def test_concurrent_parameter_flow():
    """æµ‹è¯•å¹¶å‘å‚æ•°åœ¨æ•´ä¸ªè°ƒç”¨é“¾ä¸­çš„ä¼ é€’"""
    print("\nğŸ”„ æµ‹è¯•å¹¶å‘å‚æ•°ä¼ é€’...")

    from scripts.run_primevul_concurrent_optimized import create_optimized_config

    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = create_optimized_config()

    # æ¨¡æ‹Ÿå‚æ•°æå–é€»è¾‘
    enable_batch = config.get("enable_batch_processing", False)
    batch_size = config.get("llm_batch_size", 8)
    enable_concurrent = config.get("enable_concurrent", True)

    print("ğŸ“Š å‚æ•°æå–ç»“æœ:")
    print(f"   æ‰¹å¤„ç†å¯ç”¨: {enable_batch}")
    print(f"   æ‰¹å¤§å°: {batch_size}")
    print(f"   å¹¶å‘å¯ç”¨: {enable_concurrent}")

    # éªŒè¯å‚æ•°æ­£ç¡®æ€§
    if enable_batch and batch_size == 8 and enable_concurrent:
        print("   âœ… å‚æ•°æå–æ­£ç¡®")
        return True
    else:
        print("   âŒ å‚æ•°æå–æœ‰è¯¯")
        return False


def test_sven_client_concurrent_support():
    """æµ‹è¯•SVENå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ"""
    print("\nğŸ¤– æµ‹è¯•SVENå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ...")

    try:
        from sven_llm_client import sven_llm_query

        # æ£€æŸ¥å‡½æ•°å‚æ•°

        sig = inspect.signature(sven_llm_query)
        params = list(sig.parameters.keys())

        if "concurrent" not in params:
            print("   âŒ sven_llm_queryç¼ºå°‘concurrentå‚æ•°")
            return False

        print("   âœ… sven_llm_queryæ”¯æŒconcurrentå‚æ•°")

        # æ£€æŸ¥é»˜è®¤å€¼ï¼ˆä»å…¼å®¹å‡½æ•°ï¼‰
        from evoprompt.llm.client import llm_query

        sig2 = inspect.signature(llm_query)
        concurrent_param = sig2.parameters.get("concurrent")

        if concurrent_param and concurrent_param.default:
            print("   âœ… llm_queryé»˜è®¤concurrent=True")
        else:
            print(
                f"   âš ï¸ llm_query concurrenté»˜è®¤å€¼: {concurrent_param.default if concurrent_param else 'None'}"
            )

        return True

    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_batch_processing_info():
    """æµ‹è¯•æ‰¹å¤„ç†ä¿¡æ¯æ˜¾ç¤º"""
    print("\nğŸ“Š æµ‹è¯•æ‰¹å¤„ç†ä¿¡æ¯...")

    # æ¨¡æ‹Ÿæ‰¹å¤„ç†å‚æ•°æ˜¾ç¤º
    config = {"enable_concurrent": True, "llm_batch_size": 8}
    enable_concurrent = config.get("enable_concurrent", True)
    llm_batch_size = config.get("llm_batch_size", 8)

    concurrent_text = "å¹¶å‘" if enable_concurrent else "é¡ºåº"
    info_text = f"ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ŒLLM batch_size={llm_batch_size} ({concurrent_text})"

    expected_text = "ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ŒLLM batch_size=8 (å¹¶å‘)"

    if info_text == expected_text:
        print(f"   âœ… ä¿¡æ¯æ˜¾ç¤ºæ­£ç¡®: {info_text}")
        return True
    else:
        print(f"   âŒ ä¿¡æ¯æ˜¾ç¤ºé”™è¯¯: {info_text}")
        print(f"       æœŸæœ›: {expected_text}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=== é»˜è®¤å¹¶å‘é…ç½®æµ‹è¯• ===")
    print("éªŒè¯run_primevul_concurrent_optimized.pyé»˜è®¤å¯ç”¨concurrent=True")
    print()

    tests = [
        ("é»˜è®¤å¹¶å‘é…ç½®", test_default_concurrent_config),
        ("å¹¶å‘å‚æ•°ä¼ é€’", test_concurrent_parameter_flow),
        ("SVENå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ", test_sven_client_concurrent_support),
        ("æ‰¹å¤„ç†ä¿¡æ¯æ˜¾ç¤º", test_batch_processing_info),
    ]

    results = {}

    for test_name, test_func in tests:
        print(f"ğŸ§ª æ‰§è¡Œæµ‹è¯•: {test_name}")
        try:
            result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"   ğŸ’¥ æµ‹è¯•å¼‚å¸¸: {e}")
            results[test_name] = False
        print()

    # æ€»ç»“
    passed = sum(1 for r in results.values() if r)
    total = len(results)

    print("=== æµ‹è¯•æ€»ç»“ ===")
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")

    print()
    print(f"æ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print(
            "âœ… run_primevul_concurrent_optimized.py å·²é…ç½®ä¸ºé»˜è®¤ä½¿ç”¨ concurrent=True"
        )
        print()
        print("ğŸ“ é…ç½®æ€»ç»“:")
        print("   â€¢ enable_batch_processing: True (å¯ç”¨æ‰¹å¤„ç†)")
        print("   â€¢ llm_batch_size: 8 (æ¯æ‰¹8ä¸ªè¯·æ±‚)")
        print("   â€¢ enable_concurrent: True (æ‰¹æ¬¡å†…å¹¶å‘å¤„ç†)")
        print("   â€¢ é¢„æœŸæ€§èƒ½æå‡: 2-4å€ (å–å†³äºAPIå“åº”æ—¶é—´)")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return 1


if __name__ == "__main__":
    sys.exit(main())
