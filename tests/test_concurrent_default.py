#!/usr/bin/env python3
"""
éªŒè¯run_primevul_concurrent_optimized.pyé»˜è®¤ä½¿ç”¨concurrent=True
"""

import sys
import inspect
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥scriptsæ¨¡å—
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def test_default_concurrent_config():
    """æµ‹è¯•é»˜è®¤é…ç½®æ˜¯å¦å¯ç”¨å¹¶å‘"""
    print("ğŸ”§ æµ‹è¯•é»˜è®¤å¹¶å‘é…ç½®...")

    from scripts.run_primevul_concurrent_optimized import create_optimized_config

    config = create_optimized_config()

    # æ£€æŸ¥å…³é”®é…ç½®
    required_config = {
        "enable_batch_processing": True,
        "llm_batch_size": 8,
        "enable_concurrent": True,  # è¿™æ˜¯å…³é”®
    }

    print("ğŸ“‹ æ£€æŸ¥é…ç½®é¡¹:")

    for key, expected_value in required_config.items():
        actual_value = config.get(key)
        status = "âœ…" if actual_value == expected_value else "âŒ"
        print(f"   {status} {key}: {actual_value} (æœŸæœ›: {expected_value})")
        assert actual_value == expected_value, f"{key}: {actual_value} != {expected_value}"


def test_concurrent_parameter_flow():
    """æµ‹è¯•å¹¶å‘å‚æ•°åœ¨æ•´ä¸ªè°ƒç”¨é“¾ä¸­çš„ä¼ é€’"""
    print("\nğŸ”„ æµ‹è¯•å¹¶å‘å‚æ•°ä¼ é€’...")

    from scripts.run_primevul_concurrent_optimized import create_optimized_config

    # åˆ›å»ºæµ‹è¯•é…ç½®
    config = create_optimized_config()

    # æ¨¡æ‹Ÿå‚æ•°æå–é€»è¾‘
    enable_batch = config.get("enable_batch_processing", False)
    batch_size = config.get("llm_batch_size", 8)
    enable_concurrent = config.get("enable_concurrent", True)

    print("ğŸ“Š å‚æ•°æå–ç»“æœ:")
    print(f"   æ‰¹å¤„ç†å¯ç”¨: {enable_batch}")
    print(f"   æ‰¹å¤§å°: {batch_size}")
    print(f"   å¹¶å‘å¯ç”¨: {enable_concurrent}")

    # éªŒè¯å‚æ•°æ­£ç¡®æ€§
    assert enable_batch, "æ‰¹å¤„ç†æœªå¯ç”¨"
    assert batch_size == 8, f"æ‰¹å¤§å°é”™è¯¯: {batch_size}"
    assert enable_concurrent, "å¹¶å‘æœªå¯ç”¨"
    print("   âœ… å‚æ•°æå–æ­£ç¡®")


def test_sven_client_concurrent_support():
    """æµ‹è¯•SVENå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ"""
    print("\nğŸ¤– æµ‹è¯•SVENå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ...")

    from evoprompt.llm.client import create_default_client

    # æ£€æŸ¥batch_generateæ˜¯å¦æ”¯æŒconcurrentå‚æ•°ï¼ˆé€šè¿‡kwargsï¼‰
    client = create_default_client()
    assert hasattr(client, 'batch_generate'), "å®¢æˆ·ç«¯ç¼ºå°‘batch_generateæ–¹æ³•"

    print("   âœ… å®¢æˆ·ç«¯æ”¯æŒbatch_generateæ–¹æ³•")

    # æ£€æŸ¥batch_generateæºç æ˜¯å¦å¤„ç†concurrentå‚æ•°
    import inspect
    source = inspect.getsource(client.batch_generate)
    assert "concurrent" in source, "batch_generateæœªå¤„ç†concurrentå‚æ•°"

    print("   âœ… batch_generateæ”¯æŒconcurrentå‚æ•°")


def test_batch_processing_info():
    """æµ‹è¯•æ‰¹å¤„ç†ä¿¡æ¯æ˜¾ç¤º"""
    print("\nğŸ“Š æµ‹è¯•æ‰¹å¤„ç†ä¿¡æ¯...")

    # æ¨¡æ‹Ÿæ‰¹å¤„ç†å‚æ•°æ˜¾ç¤º
    config = {"enable_concurrent": True, "llm_batch_size": 8}
    enable_concurrent = config.get("enable_concurrent", True)
    llm_batch_size = config.get("llm_batch_size", 8)

    concurrent_text = "å¹¶å‘" if enable_concurrent else "é¡ºåº"
    info_text = f"ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ŒLLM batch_size={llm_batch_size} ({concurrent_text})"

    expected_text = "ä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ŒLLM batch_size=8 (å¹¶å‘)"

    assert info_text == expected_text, f"ä¿¡æ¯æ˜¾ç¤ºé”™è¯¯: {info_text}, æœŸæœ›: {expected_text}"
    print(f"   âœ… ä¿¡æ¯æ˜¾ç¤ºæ­£ç¡®: {info_text}")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=== é»˜è®¤å¹¶å‘é…ç½®æµ‹è¯• ===")
    print("éªŒè¯run_primevul_concurrent_optimized.pyé»˜è®¤å¯ç”¨concurrent=True")
    print()

    tests = [
        ("é»˜è®¤å¹¶å‘é…ç½®", test_default_concurrent_config),
        ("å¹¶å‘å‚æ•°ä¼ é€’", test_concurrent_parameter_flow),
        ("SVENå®¢æˆ·ç«¯å¹¶å‘æ”¯æŒ", test_sven_client_concurrent_support),
        ("æ‰¹å¤„ç†ä¿¡æ¯æ˜¾ç¤º", test_batch_processing_info),
    ]

    results = {}

    for test_name, test_func in tests:
        print(f"ğŸ§ª æ‰§è¡Œæµ‹è¯•: {test_name}")
        try:
            result = test_func()
            results[test_name] = result
        except Exception as e:
            print(f"   ğŸ’¥ æµ‹è¯•å¼‚å¸¸: {e}")
            results[test_name] = False
        print()

    # æ€»ç»“
    passed = sum(1 for r in results.values() if r)
    total = len(results)

    print("=== æµ‹è¯•æ€»ç»“ ===")
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")

    print()
    print(f"æ€»ä½“ç»“æœ: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print(
            "âœ… run_primevul_concurrent_optimized.py å·²é…ç½®ä¸ºé»˜è®¤ä½¿ç”¨ concurrent=True"
        )
        print()
        print("ğŸ“ é…ç½®æ€»ç»“:")
        print("   â€¢ enable_batch_processing: True (å¯ç”¨æ‰¹å¤„ç†)")
        print("   â€¢ llm_batch_size: 8 (æ¯æ‰¹8ä¸ªè¯·æ±‚)")
        print("   â€¢ enable_concurrent: True (æ‰¹æ¬¡å†…å¹¶å‘å¤„ç†)")
        print("   â€¢ é¢„æœŸæ€§èƒ½æå‡: 2-4å€ (å–å†³äºAPIå“åº”æ—¶é—´)")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return 1


if __name__ == "__main__":
    sys.exit(main())
